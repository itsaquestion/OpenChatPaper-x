{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"..\"\n",
    "# import os \n",
    "# import sys\n",
    "# sys.path.append(os.path.abspath(path))\n",
    "# # from scipdf_utils import parse_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdf_parser import GrobidSciPDFPaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from grobid_client.grobid_client import GrobidClient\n",
    "\n",
    "# client = GrobidClient(config_path=\"../config.json\")\n",
    "# client.process(\"processFulltextDocument\", input_path=\"./inputs\",output=\"./out\", n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = GrobidSciPDFPaser(\n",
    "#             pdf_link='/data/yixin/workspace/yixin-dl-library/yxdl/projects/LLM/OpenChatPaper/examples/inputs/test.pdf',\n",
    "#         )\n",
    "# from pdf_parser import parse_pdf_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROBID_URL = \"http://localhost:8070\"\n",
    "# article_dict = parse_pdf_to_dict(\n",
    "#     \"/data/yixin/workspace/yixin-dl-library/yxdl/projects/LLM/OpenChatPaper/examples/inputs/test.pdf\",True, True, True, GROBID_URL\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/titipata/scipdf_parser\n",
    "# import scipdf\n",
    "# python -m spacy download en_core_web_sm\n",
    "# scipdf.parse_pdf_to_dict('/data/yixin/workspace/yixin-dl-library/yxdl/projects/LLM/OpenChatPaper/examples/inputs/test.pdf') # return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read full document \n",
    "# !pip install PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "pdf_link = \"https://arxiv.org/pdf/2211.08944.pdf\"\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "wFile = urllib.request.urlopen(pdf_link)\n",
    "bytes_stream = BytesIO(wFile.read())\n",
    "reader = PdfReader(bytes_stream)\n",
    "number_of_pages = len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_str = \"\"\n",
    "for i in range(number_of_pages):\n",
    "    page = reader.pages[i]\n",
    "    text = page.extract_text()\n",
    "    paper_str += \"Page \" + str(i) + \"\\n\"\n",
    "    paper_str += text + \"\\n\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = \"\"\"Q1: What problem is this paper trying to solve?\n",
    "Q2: What are the relevant studies?\n",
    "Q3: How does the paper solve this problem?\n",
    "Q4: What experiments were done in the paper?\n",
    "Q5: What gaps can be explored further?\n",
    "Q6: Summarize the main content of the paper\n",
    "\"\"\"\n",
    "\n",
    "few_shot_examples = \"\"\"\n",
    "#9 Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models\n",
    "Authors: Matthew Dahl ; Varun Magesh ; Mirac Suzgun ; Daniel E. Ho\n",
    "\n",
    "Abstract: Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations. Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources.\n",
    "\n",
    "Q: 这篇论文试图解决什么问题？\n",
    "\n",
    "A: 这篇论文试图解决的问题是大型语言模型（LLMs）在法律应用中出现的“法律幻觉”（legal hallucinations）现象。这些模型在处理法律问题时可能会生成与法律事实不一致的响应，这种现象在法律领域尤其危险，因为法律工作要求严格遵守法律文本。论文通过以下四个关键贡献来探讨这个问题：\n",
    "\n",
    "开发了一个法律幻觉的分类体系，为未来在这个领域的研究提供了概念框架。\n",
    "\n",
    "发现法律幻觉在LLMs中非常普遍，当这些模型被要求回答关于随机联邦法院案件的具体、可验证问题时，幻觉发生的比例在ChatGPT 3.5中为69%，在Llama 2中为88%。\n",
    "说明LLMs经常无法在基于反事实的法律问题设置中纠正用户的错误法律假设。\n",
    "\n",
    "提供证据表明LLMs不能总是预测，或者并不总是知道，它们何时在产生法律幻觉。\n",
    "\n",
    "这些发现警示了不应迅速且无监督地将流行的LLMs集成到法律任务中，即使是经验丰富的律师也必须对法律幻觉保持警惕，而对于那些最有可能从LLMs中受益的人——自诉当事人或无法获得传统法律资源的人来说，风险最高。\n",
    "Q: 有哪些相关研究？\n",
    "\n",
    "A: 这篇论文提到了以下几项相关研究：\n",
    "\n",
    "Choi et al., 2022：这项研究展示了LLMs在法学院一年级考试中的表现，表明LLMs在法律相关任务上的能力。\n",
    "\n",
    "OpenAI, 2023b：OpenAI的研究展示了LLMs在统一律师考试（Uniform Bar Exam）中的表现。\n",
    "\n",
    "Blair-Stanek et al., 2023：这项研究探讨了LLMs在法律推理（statutory reasoning）方面的能力。\n",
    "\n",
    "Guha et al., 2023：这项工作研究了LLMs在IRAC（Issue-Rule-Application-Conclusion）分析中的表现。\n",
    "\n",
    "Bommasani et al., 2022 和 Perlman, 2023：这些研究讨论了AI工具和系统是否可能很快取代人类律师。\n",
    "\n",
    "Weiser, 2023 和 SCOTUSBlog, 2023：这些报道提到了LLMs在法律领域中生成虚构案例引用和错误信息的问题。\n",
    "\n",
    "Ji et al., 2023; Mündler et al., 2023; Manakul et al., 2023; Dhuliawala et al., 2023：这些研究探讨了LLMs在神经机器翻译、摘要生成、一般知识问答和对话生成中的幻觉问题。\n",
    "\n",
    "Agrawal et al., 2023：这项工作提出了一种在开放领域中研究幻觉的方法，这在法律领域中特别相关，因为法律事实和文本的准确性至关重要。\n",
    "\n",
    "Kalai and Vempala, 2023：这项研究提出了LLMs在某些任务中必须产生幻觉的观点，因为它们必须为每个响应标记分配正概率。\n",
    "\n",
    "Cao et al., 2018：这项研究讨论了LLMs在摘要生成中的幻觉问题。\n",
    "\n",
    "Maynez et al., 2020：这项研究探讨了LLMs在训练或提示下对事实的忠诚度。\n",
    "\n",
    "Kleinberg and Raghavan, 2021：这项研究提出了“算法单一文化”（algorithmic monoculture）的概念，这在法律领域中可能导致LLMs对法律的过度简化理解。\n",
    "\n",
    "这些研究为理解LLMs在法律领域中的性能和局限性提供了背景，并为本文的研究提供了理论基础和实证支持。\n",
    "Q: 论文如何解决这个问题？\n",
    "\n",
    "A: 论文通过以下步骤来解决大型语言模型（LLMs）在法律领域中产生幻觉的问题：\n",
    "\n",
    "问题定义：首先，论文明确了法律幻觉的概念，即LLMs生成的与法律事实不一致的响应。这种不一致性在法律领域尤其危险，因为法律工作要求严格遵守法律文本。\n",
    "\n",
    "研究设计：论文设计了一个研究框架，通过一系列法律查询任务来评估LLMs的性能。这些任务分为低复杂度、中等复杂度和高复杂度三个类别，涵盖了从简单的案件存在性验证到复杂的法律推理。\n",
    "\n",
    "数据构建：研究者从美国联邦法院的案例法中随机抽取了5,000个案例，涵盖了最高法院（SCOTUS）、上诉法院（USCOA）和地区法院（USDC）的案例。这些案例与法律数据库中的结构化元数据相结合，用于构建参考基础查询。\n",
    "\n",
    "参考基础查询：对于有明确答案的查询，研究者直接从LLMs中获取响应，并与已知的地面真实答案进行比较，以估计幻觉率。\n",
    "\n",
    "参考自由查询：对于没有明确答案的查询，研究者采用参考自由查询方法，通过在不同的温度下重复查询LLMs并检查其响应的一致性来估计幻觉率。\n",
    "\n",
    "实验执行：使用OpenAI的ChatGPT 3.5、Google的PaLM 2和Meta的Llama 2三个流行的LLMs进行实验。\n",
    "\n",
    "结果分析：研究者分析了LLMs在不同任务上的幻觉率，并探讨了幻觉率如何随任务复杂度、法院层级、司法管辖区、案例显著性、案例年份和LLM模型本身而变化。\n",
    "\n",
    "讨论限制：论文讨论了LLMs在法律研究任务中存在的其他潜在问题，包括对反事实偏见的易感性和对响应确定性的过度自信。\n",
    "\n",
    "提出建议：基于研究结果，论文提出了对LLMs在法律领域应用的建议，强调了在将LLMs集成到法律任务中时需要谨慎，并建议法律专业人士在使用LLMs时保持警惕。\n",
    "\n",
    "通过这些步骤，论文不仅揭示了LLMs在法律领域中产生幻觉的普遍性和严重性，还为如何改进LLMs以更好地适应法律实践提供了见解。\n",
    "通过这些步骤，论文不仅揭示了LLMs在法律领域中产生幻觉的普遍性和严重性，还为如何改进LLMs以更好地适应法律实践提供了见解。\n",
    "Q: 论文做了哪些实验？\n",
    "\n",
    "A: 论文进行了以下实验来研究大型语言模型（LLMs）在法律领域中的幻觉现象：\n",
    "\n",
    "数据构建：研究者从美国联邦法院的案例法中随机抽取了5,000个案例，涵盖了最高法院（SCOTUS）、上诉法院（USCOA）和地区法院（USDC）的案例。这些案例与法律数据库中的结构化元数据相结合，用于构建参考基础查询。\n",
    "\n",
    "实验设计：研究者设计了十四个任务，分为低复杂度、中等复杂度和高复杂度三个类别，以测试LLMs在不同法律查询任务上的表现。这些任务包括验证案件存在性、提供案件引用、确定案件的法院、提供案件的主要意见作者、确定案件的判决结果、提供案件的引用、确定案件是否被推翻、确定案件的教义一致性、提供案件的事实背景、确定案件的程序立场、提供案件的后续历史、确定案件的核心法律问题和中心判决等。\n",
    "\n",
    "参考基础查询：对于有明确答案的查询，研究者直接从LLMs中获取响应，并与已知的地面真实答案进行比较，以估计幻觉率。\n",
    "\n",
    "参考自由查询：对于没有明确答案的查询，研究者采用参考自由查询方法，通过在不同的温度下重复查询LLMs并检查其响应的一致性来估计幻觉率。这种方法利用了LLMs在较高温度下生成响应时的随机性，通过比较不同温度下的响应来检测幻觉。\n",
    "\n",
    "实验执行：研究者使用OpenAI的ChatGPT 3.5、Google的PaLM 2和Meta的Llama 2三个流行的LLMs进行实验。每个查询都在零次和三次提示设置下运行。\n",
    "\n",
    "结果分析：研究者分析了LLMs在不同任务上的幻觉率，并探讨了幻觉率如何随任务复杂度、法院层级、司法管辖区、案例显著性、案例年份和LLM模型本身而变化。\n",
    "\n",
    "讨论限制：论文讨论了LLMs在法律研究任务中存在的其他潜在问题，包括对反事实偏见的易感性和对响应确定性的过度自信。\n",
    "\n",
    "这些实验旨在全面评估LLMs在法律领域中的表现，特别是在生成与法律事实一致的响应方面的能力。\n",
    "\n",
    "Q: 有什么可以进一步探索的点？\n",
    "\n",
    "A: 这篇论文提出了一些可以进一步探索的点，包括：\n",
    "\n",
    "幻觉的分类和理解：尽管论文提出了一个法律幻觉的分类体系，但这个分类可能需要进一步细化和扩展，以更好地理解不同类型的幻觉及其在法律实践中的影响。\n",
    "\n",
    "幻觉的上下文依赖性：研究可以更深入地探讨幻觉如何依赖于特定的法律上下文，例如，幻觉是否在某些法律领域更为普遍，或者是否在处理特定类型的法律问题时更容易出现。\n",
    "\n",
    "幻觉的预防和纠正：研究可以探索如何通过改进模型训练、引入外部知识库或使用人类反馈来减少幻觉的发生，并研究如何设计系统来纠正用户的错误假设。\n",
    "\n",
    "模型的自我意识：研究可以进一步探索LLMs对自己生成幻觉的自我意识，以及如何提高模型对自己不确定性的表达能力。\n",
    "\n",
    "用户交互和信任：研究可以考察用户如何与LLMs交互，以及用户如何建立对LLMs响应的信任。这包括研究用户如何识别和处理幻觉，以及如何设计用户界面来帮助用户更好地理解模型的局限性。\n",
    "\n",
    "法律实践的影响：研究可以评估LLMs在法律实践中的广泛应用对法律专业人士和公众的影响，包括对法律服务的可及性和质量的影响。\n",
    "\n",
    "伦理和社会影响：研究可以探讨LLMs在法律领域的应用可能带来的伦理和社会问题，例如，如何确保公平性和防止不平等的加剧。\n",
    "\n",
    "跨司法管辖区的比较：研究可以扩展到不同司法管辖区，比较不同法律体系中LLMs的表现，以及幻觉现象在不同法律文化中的表现形式。\n",
    "\n",
    "法律教育和培训：研究可以探讨如何利用LLMs来改进法律教育和培训，以及如何教育未来的法律专业人士理解和应对LLMs的局限性。\n",
    "\n",
    "法律政策和监管：研究可以考察如何制定法律政策和监管框架来指导LLMs在法律领域的合理使用，以及如何确保这些技术的发展符合法律伦理和职业标准。\n",
    "\n",
    "这些研究方向有助于更全面地理解LLMs在法律领域的潜力和挑战，并为未来的法律实践和技术发展提供指导。\n",
    "\n",
    "Q: 总结一下论文的主要内容\n",
    "\n",
    "A: 这篇论文探讨了大型语言模型（LLMs）在法律领域中的“法律幻觉”现象，即模型生成的响应与法律事实不一致的问题。论文的主要内容包括：\n",
    "\n",
    "研究背景：介绍了LLMs在法律领域的潜在变革作用，以及由于幻觉问题而面临的挑战。\n",
    "\n",
    "法律幻觉的类型：提出了一个法律幻觉的分类体系，区分了封闭领域和开放领域的幻觉，以及与输入提示和训练语料库的一致性问题。\n",
    "\n",
    "研究方法：设计了一套法律查询任务，分为低、中、高复杂度，以评估LLMs在不同任务上的表现。\n",
    "\n",
    "实验设计：通过随机抽取的联邦法院案例，构建了参考基础查询和参考自由查询，以估计幻觉率。\n",
    "\n",
    "实验结果：发现LLMs在回答关于随机联邦法院案件的具体、可验证问题时，幻觉发生的比例非常高，尤其是在处理复杂任务时。\n",
    "\n",
    "额外挑战：探讨了LLMs在处理基于错误法律前提的查询时的易感性，以及它们对自己生成幻觉的不确定性。\n",
    "\n",
    "讨论限制：论文讨论了LLMs在法律领域应用的局限性，包括对法律专业人士和自诉当事人的风险。\n",
    "\n",
    "结论：论文得出结论，尽管LLMs在法律研究任务上显示出潜力，但当前的局限性，特别是生成准确和可靠法律陈述的能力，严重阻碍了这一目标。\n",
    "\n",
    "论文强调了在将LLMs集成到法律任务中时需要谨慎，并建议法律专业人士在使用LLMs时保持警惕，特别是对于那些最有可能从LLMs中受益的人。\n",
    "\n",
    "#1 Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models\n",
    "Authors: Zixiang Chen ; Yihe Deng ; Huizhuo Yuan ; Kaixuan Ji ; Quanquan Gu\n",
    "\n",
    "Harnessing the power\n",
    "Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.\n",
    "\n",
    "Q: 这篇论文试图解决什么问题？\n",
    "\n",
    "A: 这篇论文试图解决的问题是：如何将一个弱的大型语言模型（LLM）通过自我博弈（self-play）机制增强为一个强大的LLM，而无需额外的人类标注数据。具体来说，论文提出了一种新的微调方法，称为Self-Play Fine-Tuning (SPIN)，它从监督微调模型开始，通过LLM与自身实例的对抗过程来提升模型能力。这种方法的核心在于，LLM通过生成自己的训练数据并从这些数据中学习，从而逐步提升性能，最终达到与人类标注数据分布一致的状态。\n",
    "\n",
    "Q: 有哪些相关研究？\n",
    "\n",
    "A: 这篇论文提到了以下几类相关研究：\n",
    "\n",
    "自我博弈（Self-Play）：自我博弈是一种学习策略，其中算法通过与自己的副本进行交互来学习。这种方法在多智能体强化学习（MARL）中得到了显著的关注，例如AlphaGo Zero和AlphaZero就是通过自我博弈机制实现的。论文中的SPIN方法借鉴了自我博弈的思想，将这一策略应用于大型语言模型的增强。\n",
    "\n",
    "合成数据用于LLMs：在监督微调（SFT）的背景下，人工制作的数据已被证明是提高LLM性能的有效来源。然而，获取足够数量的高质量数据在成本上是一个挑战。因此，使用合成数据作为人类数据的代理变得越来越流行。这种方法通常利用先进的LLM（如GPT系列）作为指导来生成高质量的数据。与之前使用更先进的模型生成合成数据的研究不同，SPIN方法直接从目标模型本身生成合成数据。\n",
    "\n",
    "课程学习（Curriculum Learning）：在深度学习中，使用按战略意义排列的数据样本进行模型训练，可以比随机打乱的数据带来更好的性能。这种方法被称为课程学习。SPIN方法与课程学习有相似之处，其中训练数据是迭代发展的——从容易与人类标注数据区分的响应开始，逐渐过渡到更具挑战性的实例。\n",
    "\n",
    "这些相关研究为SPIN方法提供了理论基础和实践背景，SPIN结合了自我博弈、合成数据生成和课程学习的思想，提出了一种新的LLM增强方法。\n",
    "\n",
    "Q: 论文如何解决这个问题？\n",
    "\n",
    "A: 论文提出了一种名为Self-Play Fine-Tuning (SPIN)的新方法来解决将弱大型语言模型（LLM）转换为强模型的问题，而无需额外的人类标注数据。SPIN的核心思想是自我博弈机制，具体步骤如下：\n",
    "\n",
    "自我博弈机制：SPIN从监督微调（SFT）模型开始，让LLM通过与自身实例的对抗来提升能力。在这个过程中，LLM既是主要玩家（试图区分人类数据和LLM生成的数据），也是对手玩家（生成尽可能接近人类数据的响应）。\n",
    "\n",
    "生成合成数据：使用当前迭代的LLM（对手玩家）为SFT数据集中的提示生成响应。这些响应作为合成数据，用于训练主要玩家。\n",
    "\n",
    "训练主要玩家：主要玩家的目标是最大化从目标数据分布到对手玩家分布的期望值差距。通过优化一个特定的目标函数，主要玩家学会区分人类标注的响应和LLM生成的响应。\n",
    "\n",
    "更新对手玩家：对手玩家的目标是生成与主要玩家难以区分的响应。这通过最大化一个结合了主要玩家评估和KL正则化的目标函数来实现，以防止模型偏离太远。\n",
    "\n",
    "迭代过程：在每个迭代中，使用上一个迭代的LLM作为对手玩家生成合成数据，然后训练主要玩家以区分这些响应。接着，根据主要玩家的评估更新对手玩家。这个过程不断迭代，直到LLM的性能达到最优。\n",
    "\n",
    "理论证明：论文提供了理论分析，证明了当LLM的策略与目标数据分布一致时，SPIN方法的全局最优解才能实现。\n",
    "\n",
    "通过这种方法，SPIN能够有效地利用人类标注的数据，通过自我博弈的过程，逐步提升LLM的性能，最终达到与人类标注数据分布一致的状态。\n",
    "\n",
    "Q: 论文做了哪些实验？\n",
    "\n",
    "A: 论文在多个基准数据集上评估了SPIN方法，包括：\n",
    "\n",
    "HuggingFace Open LLM Leaderboard：这是一个广泛使用的评估基准，涵盖了6个不同的数据集，分别针对LLM的常识推理、多任务语言理解、人类虚假陈述模仿和数学问题解决等特定能力。作者使用这个基准来评估SPIN在不同迭代下的性能提升。\n",
    "\n",
    "MT-Bench：这是一个多任务语言理解基准，用于评估模型在各种语言理解任务上的性能。\n",
    "\n",
    "Big-Bench：这是一个包含多个子任务的基准，用于评估模型在因果推理、体育理解、形式谬误和数学问题解决等任务上的性能。\n",
    "\n",
    "OpenBookQA：这是一个开放书籍问答任务，用于评估模型在问答任务上的性能。\n",
    "\n",
    "在实验中，作者展示了SPIN方法在多个数据集上显著提升了LLM的性能，甚至在某些情况下超过了通过直接偏好优化（DPO）训练的模型，尽管后者使用了额外的人类偏好数据。此外，作者还进行了消融研究，探讨了合成数据集大小和训练周期对SPIN性能的影响。实验结果表明，迭代训练是SPIN方法的关键组成部分，因为它打破了多周期训练的性能限制。\n",
    "\n",
    "Q: 有什么可以进一步探索的点？\n",
    "\n",
    "A: 尽管SPIN方法在多个基准测试中显示出了显著的性能提升，但仍有一些潜在的研究方向和改进点：\n",
    "\n",
    "动态目标数据分布：论文中的SPIN方法专注于一个固定的由人类生成的目标数据分布，这在一定程度上限制了LLM性能的提升。未来的研究可以探索如何使目标数据分布动态变化，以进一步提升LLM的性能，甚至达到超人水平。\n",
    "\n",
    "减少合成数据量：生成合成数据需要大量计算资源。研究如何减少所需的合成数据量，同时保持或提高SPIN方法的性能，是一个有前景的研究方向。\n",
    "\n",
    "自我博弈的稳定性和收敛性：虽然理论上证明了SPIN方法在满足一定条件下会收敛，但在实践中，如何确保自我博弈过程的稳定性和快速收敛仍然是一个挑战。未来的研究可以探索更有效的策略来控制自我博弈过程。\n",
    "\n",
    "应用到其他领域：SPIN方法目前主要在自然语言处理领域进行了探索。将其应用到其他领域，如计算机视觉、语音识别等，可能会带来新的洞见和挑战。\n",
    "\n",
    "自我博弈的泛化能力：研究SPIN方法在不同任务和领域中的泛化能力，以及如何通过自我博弈来提升模型的泛化性能，是一个值得探索的方向。\n",
    "\n",
    "自我博弈的可解释性：提高自我博弈过程中模型决策的可解释性，可以帮助我们更好地理解模型的内部工作机制，从而为模型的改进提供指导。\n",
    "\n",
    "自我博弈与人类交互：研究如何将自我博弈与人类交互相结合，以进一步提升模型的性能和适应性，是一个有潜力的研究方向。\n",
    "\n",
    "Q: 总结一下论文的主要内容\n",
    "\n",
    "A: 本论文提出了一种名为Self-Play Fine-Tuning (SPIN)的新方法，旨在将弱大型语言模型（LLM）通过自我博弈机制转换为强模型，而无需额外的人类标注数据。SPIN方法的核心在于LLM通过与自身实例的对抗来提升能力，其中LLM既是主要玩家（尝试区分人类数据和LLM生成的数据），也是对手玩家（生成尽可能接近人类数据的响应）。通过迭代过程，SPIN逐步提升LLM的性能，最终使其与人类标注数据分布一致。理论上，论文证明了当LLM策略与目标数据分布一致时，SPIN方法的全局最优解才能实现。实验结果表明，SPIN在多个基准数据集上显著提升了LLM的性能，甚至超过了通过直接偏好优化（DPO）训练的模型。这表明自我博弈是一个有前景的策略，可以在不依赖专家对手的情况下实现LLM的人类水平性能。\n",
    "\n",
    "#1 An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction \n",
    "Authors: Zaratiana Urchade ; Nadi Tomeh ; Pierre Holat ; Thierry Charnois\n",
    "\n",
    "In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.\n",
    "\n",
    "Q: 这篇论文试图解决什么问题？\n",
    "\n",
    "A: 这篇论文试图解决的问题是联合实体和关系抽取（Joint Entity and Relation Extraction, JERE）在自然语言处理（NLP）中面临的挑战。具体来说，论文提出了一种新的方法，通过将JERE任务框架化为一个条件序列生成问题来解决以下问题：\n",
    "\n",
    "传统的管道模型（pipeline models）独立地训练和实现实体识别和关系抽取，这往往导致错误传播。\n",
    "\n",
    "现有的端到端模型（end-to-end models）虽然允许使用共享表示和联合优化损失函数，但它们基本上仍然是基于管道的，实体和关系预测由不同的分类头执行，从而忽略了这些任务之间的潜在交互。\n",
    "现有的端到端模型（end-to-end models）虽然允许使用共享表示和联合优化损失函数，但它们基本上仍然是基于管道的，实体和关系预测由不同的分类头执行，从而忽略了这些任务之间的潜在交互。\n",
    "\n",
    "最近的进展转向了“真正的”端到端解决方案，其中实体和关系的预测是交织在一起的，通过自回归模型实现。然而，这些模型在将输出与输入文本联系起来方面存在改进空间，特别是在确保输出在语义上连贯的同时与输入文本保持上下文联系。\n",
    "\n",
    "为了解决这些问题，论文提出了一种自回归变换器编码器-解码器模型，该模型生成线性化图而不是生成纯文本。模型使用指向机制（pointing mechanism）在动态词汇表上操作跨度（spans）和关系类型，这允许捕捉实体和关系的结构特征和边界，同时通过指向机制将生成的输出与原始文本联系起来。\n",
    "\n",
    "Q: 有哪些相关研究？\n",
    "\n",
    "A: 相关研究可以分为几个主要类别，包括传统的信息抽取（IE）方法、端到端的联合实体和关系抽取模型，以及生成式信息抽取方法。以下是一些代表性的研究：\n",
    "\n",
    "传统信息抽取方法\n",
    "管道模型：这些模型通常包括独立的实体识别和关系抽取阶段，但这种方法容易受到错误传播的影响。例如，Brin (1999) 提出了一种基于规则的方法来提取实体间的关系，而 Roth 和 Yih (2004) 提出了一种线性规划方法来进行自然语言任务的全局推理。\n",
    "\n",
    "端到端模型：这些模型旨在通过联合优化损失函数来提高实体识别和关系抽取的性能。例如，Wadden 等人 (2019) 使用上下文化跨度表示进行实体、关系和事件提取。\n",
    "\n",
    "端到端的联合实体和关系抽取模型\n",
    "表填充方法：这些模型将联合信息提取任务视为表填充问题。例如，Tab-Seq (Wang 和 Lu 2020) 通过将实体和关系视为表格，并使用二维CNN来捕捉和建模局部依赖关系。\n",
    "\n",
    "统一标签空间：一些模型通过消除实体检测和关系分类的标签空间分离来实现联合提取。例如，UniRE (Wang 等人 2021) 使用统一分类器来预测单词对表中每个单元格的标签。\n",
    "\n",
    "生成式信息抽取方法\n",
    "自回归模型：这些模型将联合实体-关系任务视为生成过程，使用增强语言来编码和解码结构信息。例如，TANL (Paolini 等人 2021) 将联合信息提取任务视为从纯文本到增强自然语言的翻译过程。\n",
    "\n",
    "结构生成：一些模型通过编码目标结构作为一系列结构构建动作，并使用条件语言模型来预测这些动作来进行实体和关系提取。例如，ASP (Liu 等人 2022) 使用条件语言模型来预测结构构建动作。\n",
    "\n",
    "其他相关研究\n",
    "实体链接：Cao 等人 (2021) 提出了一种自回归实体检索方法，使用语言模型生成实体链接结果。\n",
    "\n",
    "事件提取：Li 等人 (2021) 提出了一种文档级事件论元提取方法，通过条件生成来实现。\n",
    "\n",
    "文档级关系提取：Giorgi 等人 (2022) 提出了一种序列到序列的方法来进行文档级关系提取。\n",
    "\n",
    "这些研究展示了信息抽取领域的多样性和不断发展，特别是在端到端模型和生成式模型方面的最新进展。\n",
    "Q: 论文如何解决这个问题？\n",
    "\n",
    "A: 论文提出了一个名为ATG（Autoregressive Text-to-Graph）的框架，通过以下关键方法解决了联合实体和关系提取的问题：\n",
    "\n",
    "自回归变换器编码器-解码器架构：模型使用变换器（Transformer）架构，其中编码器处理输入文本序列，解码器则生成线性化图表示。这种架构允许模型捕捉输入文本的全局上下文信息。\n",
    "\n",
    "指向机制：在解码器中使用指向机制，这允许模型在生成输出时直接引用输入文本中的特定位置。这种机制确保了生成的实体跨度与输入文本紧密关联，提供了明确的文本基础。\n",
    "\n",
    "动态词汇表：模型在解码过程中使用一个动态词汇表，其中包括跨度（spans）、特殊标记（如<SEP>）和关系类型（relation types）的嵌入。这种动态词汇表使得模型能够直接生成实体跨度和关系，而不是生成独立的纯文本。\n",
    "\n",
    "线性化图表示：模型的目标是生成一个线性化图，其中节点代表实体跨度，边代表关系三元组。这种表示形式捕捉了实体和关系的结构特征，同时保持了与原始文本的联系。\n",
    "\n",
    "约束解码：在推理阶段，模型通过状态转换约束来引导生成过程，确保输出的图结构是良好形成的。这种结构化的生成过程有助于生成有效的信息抽取图。\n",
    "\n",
    "句子增强：为了解决模型倾向于生成短序列的问题，论文提出了句子增强技术，通过随机连接训练集中的句子来增加训练样本的多样性和长度。\n",
    "\n",
    "通过这些方法，ATG框架能够有效地从非结构化文本中提取实体和关系，并以一种结构化的形式表示它们。这种表示形式不仅捕捉了实体和关系的边界，而且还通过指向机制与原始文本紧密关联，从而提高了模型的准确性和可解释性。\n",
    "Q: 论文做了哪些实验？\n",
    "\n",
    "A: 论文在三个基准数据集上评估了所提出的ATG模型：CoNLL 2004、SciERC和ACE 05。实验包括以下几个方面：\n",
    "\n",
    "模型训练：使用AdamW优化器训练模型，采用学习率预热和衰减策略。训练过程中，模型的编码器初始化为预训练的变换器编码器，而解码器是随机初始化的。\n",
    "\n",
    "基准模型比较：将ATG模型与现有的联合实体和关系提取方法进行比较，包括基于跨度的/表填充方法和生成式信息提取方法。\n",
    "\n",
    "消融研究：分析模型中不同组件的影响，例如解码器层数、位置编码和结构编码的重要性。\n",
    "\n",
    "序列排序：比较了两种不同的序列排序方法（排序和随机）对模型性能的影响。\n",
    "\n",
    "句子增强：研究了句子增强技术对模型性能的影响，特别是在不同增强大小下的性能变化。\n",
    "\n",
    "注意力分析：通过可视化模型的自注意力和交叉注意力模式，提供了模型决策过程的解释性。\n",
    "\n",
    "结构嵌入分析：分析了在训练过程中学习到的结构嵌入的相似性，以了解模型是否能够区分不同类型的结构元素（如头实体、尾实体和关系类型）。\n",
    "\n",
    "超参数调整：调整了模型的超参数，如学习率、预热步骤和衰减率，以及句子增强的超参数B。\n",
    "\n",
    "性能评估：使用实体F1分数和关系F1分数（包括边界和严格评估）来评估模型在三个数据集上的性能。\n",
    "\n",
    "这些实验旨在验证ATG模型的有效性，并通过与现有方法的比较来展示其竞争力。此外，消融研究和注意力分析有助于理解模型的内部工作机制。\n",
    "Q: 有什么可以进一步探索的点？\n",
    "\n",
    "A: 尽管论文提出了一种有效的联合实体和关系提取方法，但仍有一些潜在的研究方向可以进一步探索：\n",
    "\n",
    "模型解释性：虽然论文通过注意力分析提供了模型决策过程的一些见解，但可以进一步研究模型的可解释性，例如通过更深入的模型解释技术，如LIME或SHAP。\n",
    "\n",
    "多语言和跨领域泛化：论文主要在英文数据集上进行了实验。研究模型在多语言和跨领域数据上的泛化能力，以及如何适应不同的语言和领域，是一个有趣的方向。\n",
    "\n",
    "实体和关系的多样性：论文中的数据集主要关注有限的实体和关系类型。研究模型如何处理更多样化的实体和关系类型，特别是在复杂或领域特定的文本中，可能是一个挑战。\n",
    "\n",
    "上下文敏感性：虽然自回归模型在一定程度上考虑了上下文，但可以探索更复杂的上下文建模技术，如上下文变换器或记忆增强模型，以提高模型对长距离依赖的捕捉能力。\n",
    "\n",
    "生成质量：论文主要关注模型在实体和关系抽取任务上的性能，但可以进一步研究生成的图结构的质量，例如通过人工评估或图结构分析。\n",
    "\n",
    "知识图谱集成：论文将实体和关系提取视为构建知识图谱的基础任务。研究如何将提取的实体和关系有效地集成到知识图谱中，以及如何利用知识图谱来指导提取过程，是一个有前景的方向。\n",
    "\n",
    "实时和增量学习：现有的模型训练和评估通常是离线的。研究如何使模型能够进行实时学习和增量更新，以适应动态变化的数据和环境，具有实际应用价值。\n",
    "\n",
    "模型压缩和优化：为了在资源受限的设备上部署模型，研究模型压缩和优化技术，如知识蒸馏、模型剪枝和量化，是必要的。\n",
    "\n",
    "这些方向不仅有助于提高现有模型的性能，还可以推动信息抽取和自然语言处理领域的整体进步。\n",
    "\n",
    "Q: 总结一下论文的主要内容\n",
    "\n",
    "A: 这篇论文提出了一种名为ATG（Autoregressive Text-to-Graph）的新型方法，用于从非结构化文本中联合提取实体和关系。以下是论文的主要内容总结：\n",
    "\n",
    "目标：解决传统信息抽取方法中的错误传播问题，并提高现有端到端模型在实体和关系预测中的交互性。\n",
    "\n",
    "方法：\n",
    "\n",
    "自回归变换器编码器-解码器架构：使用变换器架构处理输入文本序列，并生成线性化图表示，其中节点代表实体跨度，边代表关系三元组。\n",
    "\n",
    "指向机制：在解码器中使用指向机制，确保生成的实体跨度直接与输入文本关联。\n",
    "\n",
    "动态词汇表：包含跨度、特殊标记和关系类型嵌入的动态词汇表，允许直接从文本生成结构。\n",
    "\n",
    "约束解码：在推理阶段使用状态转换约束，确保输出图结构的完整性。\n",
    "\n",
    "实验：\n",
    "\n",
    "在CoNLL 2004、SciERC和ACE 05三个基准数据集上进行评估。\n",
    "与现有的联合实体和关系提取方法进行比较，包括基于跨度的/表填充方法和生成式信息提取方法。\n",
    "\n",
    "进行了消融研究，分析了模型组件的影响，如解码器层数、位置编码和结构编码。\n",
    "\n",
    "结果：\n",
    "\n",
    "ATG模型在所有数据集上展现出竞争力，特别是在SciERC和CoNLL 2004数据集上取得了最先进的结果。\n",
    "\n",
    "模型通过自注意力和交叉注意力可视化展示了对输入文本的理解和利用。\n",
    "\n",
    "注意力分析揭示了模型在生成实体和关系时的决策过程。\n",
    "结论：\n",
    "\n",
    "ATG框架通过直接生成线性化图表示，成功捕捉了实体和关系的结构特征、边界和交互性。\n",
    "\n",
    "指向机制提供了与原始文本的强有力联系，而动态词汇表则允许模型以更紧凑的形式表示信息。\n",
    "未来工作：\n",
    "\n",
    "提高模型的解释性，特别是在理解模型如何区分不同类型的结构元素方面。\n",
    "\n",
    "探索多语言和跨领域泛化，以及在更复杂或领域特定文本中的应用。\n",
    "研究实时和增量学习，以便在资源受限的环境中部署模型。\n",
    "\n",
    "#2 LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning\n",
    "Authors: Hongye Jin ; Xiaotian Han ; Jingfeng Yang ; Zhimeng Jiang ; Zirui Liu ; Chia-Yuan Chang ; Huiyuan Chen ; Xia Hu\n",
    "\n",
    "This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length.\n",
    "\n",
    "Q: 这篇论文试图解决什么问题？\n",
    "\n",
    "A: 这篇论文试图解决大型语言模型（LLMs）在处理长输入序列时的局限性问题。具体来说，论文关注以下几个核心问题：\n",
    "\n",
    "LLMs在预训练阶段的序列长度限制：由于LLMs在训练时使用固定长度的序列，这限制了它们在推理阶段处理超出预训练上下文窗口长度的长输入序列的能力。\n",
    "\n",
    "长上下文处理能力：论文认为现有的LLMs本身具有处理长上下文的固有能力，但由于预训练时的相对位置编码（如RoPE）在推理时遇到未见过的相对位置（out-of-distribution, O.O.D.），导致性能下降。\n",
    "\n",
    "无需微调的上下文窗口扩展方法：论文提出一种名为Self-Extend的方法，旨在通过简单的修改来扩展LLMs的上下文窗口，而无需任何微调。这通过在推理阶段应用FLOOR操作来映射未见过的相对位置到训练阶段已知的位置来实现。\n",
    "\n",
    "性能评估：论文通过语言建模、合成长上下文任务和真实世界长上下文任务来评估Self-Extend方法的有效性，并与现有的微调方法进行比较。\n",
    "\n",
    "短上下文任务的性能保持：论文还探讨了Self-Extend方法在短上下文任务上的性能，以确保扩展上下文窗口的同时不会损害模型在标准任务上的表现。\n",
    "\n",
    "总结来说，这篇论文旨在通过提出一种无需微调的方法来扩展LLMs的上下文窗口，以充分利用它们的固有能力来处理长输入序列，并在各种任务上进行性能评估。\n",
    "\n",
    "Q: 有哪些相关研究？\n",
    "\n",
    "A: 这篇论文中提到了多个相关研究，它们主要集中在如何扩展大型语言模型（LLMs）的上下文窗口，以及如何提高LLMs处理长序列的能力。以下是一些关键的相关研究：\n",
    "\n",
    "Xiong et al. (2023): 提出了一种通过微调模型来扩展上下文窗口的方法，这种方法需要在大量扩展文本上进行微调。\n",
    "\n",
    "Chen et al. (2023a, 2023b): 提出了'CLEX'和'PI'两种方法，它们旨在通过不同的方式扩展上下文窗口，但通常需要一些微调步骤。\n",
    "\n",
    "Peng et al. (2023b): 提出了'Yarn'方法，这是一种基于微调的上下文窗口扩展技术。\n",
    "\n",
    "Xiao et al. (2023): 提出了一种避免微调的方法，主要依赖于序列中的局部信息，但可能在有效扩展上下文窗口方面存在局限性。\n",
    "\n",
    "Han et al. (2023): 提出了'Lm-infinite'方法，这是一种简单的在线长度泛化技术，用于扩展LLMs。\n",
    "\n",
    "Ding et al. (2023): 提出了'Longnet'方法，用于扩展Transformer模型以处理更长的序列。\n",
    "\n",
    "Su et al. (2023): 提出了RoPE（Rotary Position Embedding）技术，用于在Transformer模型中处理长序列。\n",
    "\n",
    "Zaheer et al. (2020): 提出了Big Bird模型，这是一种为长序列设计的Transformer模型。\n",
    "\n",
    "Dai et al. (2019): 提出了Transformer-XL模型，它通过注意力衰减来处理长序列。\n",
    "\n",
    "Brown et al. (2020): 提出了GPT-3模型，它使用了学习到的位置嵌入。\n",
    "\n",
    "Vaswani et al. (2017): 提出了原始的Transformer模型，这是许多后续模型的基础。\n",
    "\n",
    "这些研究为LLMs在处理长序列方面的挑战提供了不同的解决方案，包括微调、位置编码的改进、注意力机制的设计等。论文提出的Self-Extend方法试图在不进行微调的情况下，通过扩展上下文窗口来提高LLMs处理长序列的能力。\n",
    "\n",
    "Q: 论文如何解决这个问题？\n",
    "\n",
    "A: 论文提出了一种名为Self-Extend的方法来解决大型语言模型（LLMs）在处理长输入序列时的局限性问题。Self-Extend的核心思想是通过构建双级注意力信息（group level和neighbor level）来扩展LLMs的上下文窗口，而无需进行任何微调。以下是Self-Extend方法的关键步骤：\n",
    "\n",
    "双级注意力机制：Self-Extend引入了两种级别的注意力机制。第一级是组级别（group level），用于处理长距离的token；第二级是邻居级别（neighbor level），用于处理一定范围内的相邻token。\n",
    "\n",
    "FLOOR操作：为了解决预训练时未见过的相对位置（O.O.D.）问题，Self-Extend在组级别上应用了FLOOR（整数除法）操作。这个操作将未见过的大的相对位置映射到预训练时已知的位置，从而允许LLMs在不进行微调的情况下维护更长文本的连贯性。\n",
    "\n",
    "注意力合并：在合并组级别和邻居级别的注意力时，Self-Extend通过替换邻居token窗口外的注意力值来实现。这样，模型在生成特定token时，仍然能够精确地建模邻居token。\n",
    "\n",
    "无需微调：Self-Extend仅在推理阶段修改注意力机制，不需要任何训练或微调。这使得它成为一个即插即用的解决方案，可以轻松地应用于现有的LLMs。\n",
    "\n",
    "性能评估：论文通过在语言建模、合成长上下文任务和真实世界长上下文任务上的实验来评估Self-Extend的有效性。结果表明，Self-Extend能够有效地扩展现有LLMs的上下文窗口长度，并且在某些任务上甚至超过了基于微调的方法。\n",
    "\n",
    "总结来说，Self-Extend通过在不进行微调的情况下扩展LLMs的上下文窗口，利用了LLMs处理长序列的固有能力。通过引入双级注意力机制和FLOOR操作，Self-Extend能够在不牺牲短序列性能的前提下，显著提高LLMs在长序列任务上的性能。\n",
    "\n",
    "Q: 论文做了哪些实验？\n",
    "\n",
    "A: 论文中进行了一系列的实验来评估提出的Self-Extend方法在不同任务上的性能。以下是主要的实验内容：\n",
    "\n",
    "语言建模性能：在PG19数据集上评估Self-Extend在不同序列长度下的困惑度（Perplexity, PPL）。这可以帮助理解Self-Extend在语言建模任务上的表现，尤其是在超出预训练上下文窗口长度时的性能。\n",
    "\n",
    "合成长上下文任务：通过Passkey检索任务来测试模型在长序列中检索信息的能力。这个任务要求模型在长文本序列中找到特定的信息（如随机放置的五位数密码），以评估其对长距离信息的敏感性。\n",
    "\n",
    "真实世界长上下文任务：使用两个真实世界的数据集LongBench和L-Eval来评估Self-Extend在处理长上下文任务时的性能。这些数据集包含了多种长文本理解任务，如问答、摘要和多文档问答等。\n",
    "\n",
    "短上下文任务：在Hugging Face Open LLM Leaderboard上评估Self-Extend在标准短上下文任务上的性能，包括ARC-Challenge、HellaSwag、MMLU、TruthfulQA和GSM8K。这有助于了解Self-Extend是否会影响模型在短序列任务上的表现。\n",
    "\n",
    "消融研究：研究了组大小（group size）和邻居窗口大小（neighbor window）对Self-Extend性能的影响。这有助于理解这些超参数对模型性能的具体影响。\n",
    "\n",
    "通过这些实验，论文展示了Self-Extend在不同类型任务上的有效性，特别是在扩展上下文窗口长度方面。实验结果表明，Self-Extend能够在不进行微调的情况下显著提高LLMs处理长序列的能力，并且在某些任务上甚至超过了基于微调的方法。此外，Self-Extend在短上下文任务上的性能几乎不受影响，表明其对模型原有性能的兼容性。\n",
    "\n",
    "Q: 有什么可以进一步探索的点？\n",
    "\n",
    "A: 论文提出了Self-Extend方法来扩展大型语言模型（LLMs）的上下文窗口，但仍有一些潜在的研究方向可以进一步探索：\n",
    "\n",
    "更高效的注意力机制：虽然Self-Extend通过FLOOR操作简化了长距离注意力计算，但这种方法可能在处理更长序列时效率不高。可以考虑更高效的注意力机制，如Flash Attention（Dao et al., 2022），以提高处理长序列的效率。\n",
    "\n",
    "更复杂的映射方法：论文中使用了简单的FLOOR操作来映射未见过的相对位置。可以尝试更复杂的映射方法，以实现更好的长上下文理解能力和更长的上下文窗口扩展。\n",
    "\n",
    "不同位置编码的模型：Self-Extend是基于RoPE位置编码的模型提出的。可以探索在其他类型的位置编码（如绝对位置编码）上应用Self-Extend，以验证其普适性。\n",
    "\n",
    "更大的模型和更长的上下文：论文中使用的模型和上下文长度可能限制了Self-Extend的潜力。在更大的模型和更长的上下文长度上测试Self-Extend，可以帮助我们更好地理解其在实际应用中的性能。\n",
    "\n",
    "长上下文任务的标准化评估：目前对于长上下文任务的评估标准并不统一，这可能导致评估结果的不一致。开发标准化的评估方法可以帮助更准确地衡量模型在长上下文理解上的能力。\n",
    "\n",
    "模型的泛化能力：虽然Self-Extend在某些任务上表现良好，但其泛化能力，特别是在未见过的长序列上的表现，仍需进一步研究。\n",
    "\n",
    "模型的可解释性：理解Self-Extend如何影响模型的内部表示和注意力分布，可以提供关于其工作原理的洞察，并可能指导未来的改进。\n",
    "\n",
    "计算资源的优化：考虑到长序列处理对计算资源的需求，探索如何优化Self-Extend以减少计算成本也是一个重要的研究方向。\n",
    "\n",
    "通过这些进一步的探索，可以更深入地理解Self-Extend的工作原理，优化其性能，并扩展其在长上下文理解任务中的应用。\n",
    "\n",
    "Q: 总结一下论文的主要内容\n",
    "\n",
    "A: 这篇论文提出了一种名为Self-Extend的方法，旨在扩展大型语言模型（LLMs）的上下文窗口，以便更好地处理长输入序列，而无需进行微调。以下是论文的主要内容总结：\n",
    "\n",
    "背景与动机：\n",
    "\n",
    "LLMs在处理长输入序列时面临挑战，因为它们的训练序列长度有限，这限制了它们在推理阶段处理超出预训练上下文窗口长度的序列的能力。\n",
    "\n",
    "论文认为现有的LLMs本身具有处理长上下文的固有能力，但受限于预训练时的相对位置编码（如RoPE）在推理时遇到未见过的相对位置（O.O.D.）问题。\n",
    "\n",
    "提出的方法：\n",
    "\n",
    "Self-Extend通过构建双级注意力信息（组级别和邻居级别）来扩展LLMs的上下文窗口。\n",
    "\n",
    "组级别注意力用于处理长距离token，通过FLOOR操作将未见过的大相对位置映射到已知位置。\n",
    "\n",
    "邻居级别注意力用于处理一定范围内的相邻token，保持原有的注意力机制不变。\n",
    "\n",
    "实验评估：\n",
    "\n",
    "在语言建模、合成长上下文任务（如Passkey检索）和真实世界长上下文任务（如LongBench和L-Eval数据集）上进行了广泛的实验。\n",
    "\n",
    "Self-Extend在不进行微调的情况下，能够有效地扩展现有LLMs的上下文窗口长度，并在某些任务上超过了基于微调的方法。\n",
    "\n",
    "主要贡献：\n",
    "\n",
    "提出了Self-Extend方法，无需微调即可扩展LLMs的上下文窗口。\n",
    "\n",
    "通过实验证明了Self-Extend在处理长上下文任务上的优越性能。\n",
    "\n",
    "强调了LLMs处理长上下文的潜在能力，并展示了通过简单的修改即可实现上下文窗口扩展的可能性。\n",
    "\n",
    "讨论与未来工作：\n",
    "\n",
    "Self-Extend的局限性包括缺乏Flash Attention的实现和在过大的组大小下的性能下降。\n",
    "\n",
    "未来的工作包括实现Flash Attention以提高效率，测试Self-Extend在其他位置编码模型上的性能，以及探索更复杂的映射方法来实现更长的上下文窗口扩展。\n",
    "\n",
    "总的来说，论文提出了一种新颖的方法来扩展LLMs的上下文窗口，以更好地处理长序列输入，并通过实验验证了其有效性。这为LLMs在长上下文理解任务中的应用提供了新的思路。\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful Paper Summary Tool, please first read the parsed text of a given paper, and answer six questions on the paper in chinese language.\n",
    "\n",
    "// paper information\n",
    "{paper_context}\n",
    "\n",
    "// questions\n",
    "{questions}\n",
    "\n",
    "// some good answer samples for other papers\n",
    "{few_shot_examples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are a helpful Paper Summary Tool, please first read the parsed text of a given paper, and answer six questions on the paper in chinese language.\\n\\n// paper information\\nPage 0\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones:\\nRobustness, Consistency and Perceptual Quality\\nGuy Ohayon1Theo Adrai1Michael Elad1Tomer Michaeli2\\nAbstract\\nStochastic restoration algorithms allow to explore\\nthe space of solutions that correspond to the de-\\ngraded input. In this paper we reveal additional\\nfundamental advantages of stochastic methods\\nover deterministic ones, which further motivate\\ntheir use. First, we prove that any restoration\\nalgorithm that attains perfect perceptual quality\\nand whose outputs are consistent with the input\\nmust be a posterior sampler, and is thus required\\nto be stochastic. Second, we illustrate that while\\ndeterministic restoration algorithms may attain\\nhigh perceptual quality, this can be achieved only\\nby filling up the space of all possible source im-\\nages using an extremely sensitive mapping, which\\nmakes them highly vulnerable to adversarial at-\\ntacks. Indeed, we show that enforcing determinis-\\ntic models to be robust to such attacks profoundly\\nhinders their perceptual quality, while robustify-\\ning stochastic models hardly influences their per-\\nceptual quality, and improves their output variabil-\\nity. These findings provide a motivation to foster\\nprogress in stochastic restoration methods, paving\\nthe way to better recovery algorithms.\\n1. Introduction\\nImage restoration has a central role in imaging sciences, en-\\nabling much of the imaging revolution we see today. Mod-\\nern restoration methods allow to squeeze out ever fantastic\\nquality from ever smaller sensors (e.g. on mobile devices),\\nwhich are prone to severe noise, blur, limited resolution,\\nand color degradations. Traditionally, most image restora-\\ntion algorithms were deterministic: providing one restored\\nimage for a given degraded input. Stochastic restoration\\n1Faculty of Computer Science, Technion, Haifa, Israel\\n2Faculty of Electrical and Computer Engineering, Technion,\\nHaifa, Israel. Correspondence to: Guy Ohayon <ohay-\\nonguy@campus.technion.ac.il >.\\nProceedings of the 40thInternational Conference on Machine\\nLearning , Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright\\n2023 by the author(s).algorithms, which started to receive notable attention in re-\\ncent years (Lugmayr et al., 2021; 2022; Bahat & Michaeli,\\n2020; Ohayon et al., 2021; Kawar et al., 2022; 2021b;a;\\nSaharia et al., 2021; Kadkhodaie & Simoncelli, 2021; Song\\n& Ermon, 2019), instead sample from a distribution condi-\\ntioned on the degraded input. Yet, beyond their core ability\\nto explore the space of possible solutions, the advantages of\\nstochastic methods over deterministic ones are still unclear.\\nFor instance, a fundamental mystery is whether stochastic\\nrestoration algorithms are theoretically superior to deter-\\nministic ones in terms of the achievable perceptual quality,\\nthe robustness to adversarial attacks, and the faithfulness of\\nthe results to the measurements (a property we refer to as\\nconsistency).\\nIn this paper we provide novel justifications for using\\nstochastic restoration methods. First, we show that any esti-\\nmator that generates consistent restorations and attains per-\\nfect perceptual quality must be sampling from the posterior\\ndistribution. An immediate, yet significant, consequence\\nis that if a deterministic restoration algorithm is consistent\\nthen it cannot attain perfect perceptual quality1. Somewhat\\nstrangely, despite this theoretical limitation, deterministic\\nrestoration algorithms are known to be able to attain high\\nperceptual quality, or at least produce images with high pre-\\ncision (Wang et al., 2018; Blau & Michaeli, 2018; Ledig\\net al., 2017; Yu et al., 2018b;b; Zhao et al., 2021; Yi et al.,\\n2020). While this may seem as a contradiction, we argue\\nthat it is not. We show empirically that, in order to cope with\\nthe lack of output diversity, such deterministic estimators\\nadopt an erratic2output behavior in an attempt to “fill up”\\nthe space of all possible natural images, so as to minimize\\nthe distance between the distribution of their outputs and the\\ndistribution of natural images. As a result, such estimators\\nare highly sensitive to small changes in their input. Indeed,\\n1Unless the posterior assigns nonzero probability to only one\\nreconstruction for every input, in which case the inverse problem\\nis non-ambiguous and it is possible to restore images with zero\\nerror.\\n2By erratic we mean that the restoration algorithm is not robust\\nto an input adversarial attack: a small, unnoticeable change in the\\ninput degraded image may lead to an unreasonably large change in\\nthe output estimated image. I.e., the value of Equation (5) is too\\nhigh.\\n1\\n\\nPage 1\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nStochastic Deterministic\\nInput Erratic Robust Erratic Robust\\nFigure 1. Output samples from several consistent restoration algorithms that solve the image inpainting task on the CelebA data set. The\\nerratic stochastic and deterministic algorithms are trained solely with a GAN loss. As can be seen, the erratic stochastic estimator barely\\nproduces output variability per input, which reveals a tendency of mode collapse of CGANs (Goodfellow et al., 2014; Isola et al., 2017;\\nMathieu et al., 2016; Yang et al., 2019; Ohayon et al., 2021). The robust algorithms are trained to also defend against adversarial attacks\\nby adding Equation (7) to the GAN objective. Robustifying the deterministic algorithm deteriorates its perceptual quality, while doing\\nso for the stochastic algorithm preserves this quality and significantly improves its output variability. Refer to Table 1 for quantitative\\nevaluation.\\nit has been experimentally observed that a visually unno-\\nticeable input perturbation leads to unreasonable changes\\nin the output in this kind of estimators (Choi et al., 2019;\\n2021; Antun et al., 2020; Yan et al., 2022; Raj et al., 2020;\\nGandikota et al., 2022; Yu et al., 2022; Choi et al., 2020;\\nYue et al., 2021). Furthermore, we illustrate that making\\ndeterministic methods more robust to adversarial attacks\\ncauses the quality of their outputs to deteriorate (see Fig-\\nure 1). Hence, our findings provide a novel explanation\\nfor the increased vulnerability of high perceptual quality\\ndeterministic estimators to adversarial attacks.\\nSince robustness for deterministic estimators comes at the\\nexpense of perceptual quality, it is appealing to resort to\\nstochastic estimators. Such estimators can produce many\\nrestorations for any given input, so that they seemingly do\\nnot need to be highly sensitive to their inputs. Indeed, we\\nshow that as opposed to deterministic methods, robustifying\\nstochastic algorithms hardly impairs their perceptual quality.\\nInterestingly, some stochastic methods do exhibit a rela-\\ntively high sensitivity to their inputs, but this is indicative\\nof mode-collapse (they effectively behave like determinis-\\ntic methods). As we illustrate in Figure 1, in such cases\\nrobustification improves the output diversity without ham-\\npering perceptual quality. All at all, unlike deterministic\\nalgorithms, stochastic methods allow to attain consistent,high perceptual quality restorations, while remaining robust\\nto adversarial attacks.\\nThe contributions of this paper are the following: 1) We\\nprove that a posterior sampler is the only consistent restora-\\ntion algorithm that attains perfect perceptual quality; 2)\\nWhile deterministic restoration algorithms could still be\\nconsistent and attain very high perceptual quality, we re-\\nveal that they behave erratically in order to do so, i.e., we\\nempirically show that for deterministic estimators, high\\nperceptual quality comes with the cost of vulnerability to\\ninput adversarial attacks; 3) We develop a novel notion of\\nrobustness for stochastic estimators; and 4) We show that\\nrobustifying deterministic algorithms deteriorates their per-\\nceptual quality, while doing so for stochastic algorithms\\nonly improves their output diversity. Hence, we empirically\\nconfirm that stochastic restoration algorithms can be robust\\nand attain high perceptual quality at the same time. We thus\\nsuggest robustness as an effective regularization for promot-\\ning meaningful diversity in stochastic restoration methods.\\nPlease refer to Figure 2 for a flow chart that clarifies the\\nmain conclusions of this paper.\\n2\\n\\nPage 2\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nStochastic Deterministic\\nConsistent restoration algorithm\\nLow perceptual\\nqualityMay attain high\\nperceptual qualityNo output\\nvariability\\nYes NoRobust?Yes NoRobust?\\nMay attain high\\nperceptual quality\\nLow output\\nvariabilityHigh output\\nvariability\\nWhat often happens if the estimator is a stochastic network,\\ntrained as a GAN, and attains high perceptual quality\\nFigure 2. The main conclusions of this paper, summarized in a flow chart. We only consider perfectly consistent restoration algorithms. A\\ndeterministic restoration algorithm has, by definition, no output variability. Such an algorithm attains low perceptual quality if it is robust,\\nand may attain high perceptual quality otherwise. A stochastic restoration algorithm may always attain high perceptual quality, whether it\\nis robust or not. In the case where the stochastic algorithm is a neural network trained as a GAN, robustifying such an algorithm improves\\n(increases) its output variation per input. Without robustification, such an algorithm often attains low output variability, and essentially\\nbehaves as a non-robust (erratic), deterministic algorithm.\\n2. Problem setting and preliminaries\\nWe consider a natural image x∈Rnxas a realization of\\na multivariate random variable Xwith probability density\\nfunction pX. A degraded version y∈Rnyis also a re-\\nalization of a random vector Ywhich is related to Xvia\\nsome conditional distribution pY|X. In this paper we as-\\nsume that the degradation is deterministic, i.e., y=D(x),\\nwhich implies that pY|X(y|x) = δ(y−D(x)), where\\nD:Rnx→Rnyis a non-invertible function. Problems\\nsuch as image colorization, inpainting, demosaicing, single-\\nimage super-resolution, JPEG-deblocking, and more all fol-\\nlow this assumed structure. Here we focus on ill-posed\\ninverse problems in which Xcannot be retrieved from Y\\nwith zero error, i.e., pX|Y(·|y)is not a delta function for\\nalmost every y.\\nGiven a particular input Y=y, an image restoration al-\\ngorithm produces an estimate ˆXaccording to some distri-\\nbution pˆX|Y(·|y)such that the estimate ˆXis statistically\\nindependent of Xgiven Y. For deterministic algorithms,\\npˆX|Y(·|y)is a delta function for every y, while for stochastic\\nalgorithms it is a non-degenerate distribution.2.1. Perceptual quality\\nConceptually, the perceptual quality of a restoration algo-\\nrithm is a quantification of its ability to produce images that\\nappear natural. While there are several notions of perceptual\\nquality, we measure it as the deviation of the restorations\\nfrom natural image statistics (Blau & Michaeli, 2018). For-\\nmally, we quantify the perceptual quality of an estimator ˆX\\nusing the perceptual index (lower is better),\\nd(pX, pˆX), (1)\\nwhere d(p, q)is a divergence between distributions (e.g.,\\nKullback-Leibler, Wasserstein). i.e., an estimator attains\\nperfect perceptual quality if pˆX=pX. As discussed in (Saj-\\njadi et al., 2018; Kynk ¨a¨anniemi et al., 2019), one can mea-\\nsure the deviation between pˆXandpXviaprecision (the\\nprobability that a random sample from pˆXfalls within the\\nsupport of pX) and recall (the probability that a random\\nsample from pXfalls within the support of pˆX). Such an\\napproach to measure statistical deviation is useful since it\\nprovides a meaning to the difference between pˆXandpX,\\nif exists. That is, low precision means that a sample of ˆX\\nmay seem unnatural, while low recall implies that part of\\nthe support of pX(possible natural images) can never be\\nthe output of ˆX. Note that pˆX=pXif and only if both\\nthe precision and recall are perfect (Sajjadi et al., 2018).\\n3\\n\\nPage 3\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nImportantly, the reader should not confuse high precision\\nwith high perceptual quality. A restoration algorithm might\\nproduce images that appear natural (with high precision),\\nbut this does not mean that the algorithm attains sufficient\\nperceptual quality, since its recall might be compromised.\\n2.2. Consistency\\nAnother important quality measure of a restoration algo-\\nrithm is its ability to produce results that are consistent with\\nthe low quality input. Such an ability is important to con-\\nsider since only perfectly consistent restorations could poten-\\ntially be the high quality source image. In our deterministic\\ndegradation scenario, a restoration ˆxis consistent if it satis-\\nfiesD(ˆx) =y(which in turn equals D(x)), which can be\\nequivalently written as pY|X(·|x) =pY|ˆX(·|x). We regard\\nan algorithm as perfectly consistent (or consistent, in short)\\nif it satisfies this property for every x. Note that a restoration\\nalgorithm that is not perfectly consistent could still be con-\\nsidered as such for any practical use. For instance, (Lugmayr\\net al., 2022; 2021) consider super-resolution (SR) methods\\nas consistent if they satisfy PSNR (D(ˆX), D(X))≥45dB.\\nWhile being an important property for restoration algo-\\nrithms, apparently only recent publications provide a report\\nof consistency (Lugmayr et al., 2022; Jo et al., 2021; Lug-\\nmayr et al., 2020; 2021; Bahat & Michaeli, 2020; Kim et al.,\\n2015), while many previous ones do not (Wang et al., 2018;\\nChen et al., 2018; Ledig et al., 2017; Shi et al., 2016; Dong\\net al., 2015). Moreover, works that do report consistency\\ntypically deal only with stochastic image restoration. It\\ntherefore seems that consistency has been overlooked, or\\ntaken for granted by deterministic restoration algorithms.\\n3. Can deterministic estimators be consistent\\nand achieve high perceptual quality?\\nWhile deterministic algorithms are being extensively used\\nto produce high perceptual quality restorations (e.g., (Wang\\net al., 2018; Ledig et al., 2017; Yu et al., 2018b;b; Zhao et al.,\\n2021; Yi et al., 2020; Galteri et al., 2017)), the following\\nimportant result must be taken into account.\\nTheorem 3.1. For a deterministic degradation, y=D(x),\\nan estimator ˆXis perfectly consistent ( pY|X=pY|ˆX) and\\nachieves perfect perceptual quality ( pˆX=pX) if and only\\nif it is the posterior sampler pˆX|Y=pX|Y.\\nThe proof of the theorem makes simple use of Bayes’ rule\\n(see Appendix A). But despite its simplicity, this result has\\nseveral important implications. (i) Since pX|Y(·|y)is not\\na delta function for almost every y(the degradation is not\\ninvertible), an immediate corollary is that a consistent de-\\nterministic algorithm can never attain perfect perceptual\\nquality . (ii) It is a known fact that there are cases in which\\nthe posterior sampler does not attain the lowest possibleMSE (or any other distortion measure) among the estimators\\nthat achieve perfect perceptual quality (Blau & Michaeli,\\n2018; Freirich et al., 2021). But from Theorem 3.1 we see\\nthatthe posterior sampler is the only perfect perceptual\\nquality estimator that is also perfectly consistent . Thus, for\\nperfect perceptual quality estimators, aiming for low dis-\\ntortion might come on the expense of inconsistency. (iii)\\nFinally, we can conclude from Theorem 3.1 that if perfect\\nconsistency is enforced, then one can train a restoration algo-\\nrithm to become a posterior sampler by solely encouraging\\nhigh perceptual quality (e.g. with a GAN loss), without any\\nadditional loss.\\n4.Erratic behavior of deterministic estimators\\nEarlier work (Choi et al., 2019; 2021) has already identified\\nthe tendency of deterministic GAN-based restoration meth-\\nods to be vulnerable to adversarial attacks. In this section\\nwe shed light on this phenomenon. The authors of both of\\nthese works hypothesize that, since GANs usually produce\\nperceptually appealing and sharp textures, small input per-\\nturbations tend to be severely intensified in the output image.\\nWhile such a claim is valid, it does not tell the full story. We\\nargue that this phenomenon is indeed a result of attempting\\nto attain high perceptual quality, but more specifically, doing\\nsowith a deterministic estimator . To attain high perceptual\\nquality, such an estimator must adopt an erratic output be-\\nhavior in order to fill up the space of possible source signals,\\nand consequently be highly sensitive to small input perturba-\\ntions (i.e., vulnerable to adversarial attacks). In other words,\\nthe problem is not related to the use of GANs, but rather to\\nthe lack of randomness. Using any non-GAN-based deter-\\nministic method with high perceptual quality would yield\\nthe same issue; and a GAN-based stochastic method with\\nhigh perceptual quality can avoid this phenomenon. Refer\\nto Appendix B for further discussion.\\nLet us demonstrate this phenomenon in more detail through\\na toy experiment. Suppose that X= (X(1), X(2))is uni-\\nformly distributed on a disk with radius 1.0centered at\\n(0,0), and let Y=X(1). Our goal is to estimate Xbased\\nonY(i.e., we need to estimate only X(2), asX(1)is known).\\nIn Figure 3 (the two leftmost columns in the top row) we\\npresent two consistent deterministic restoration algorithms\\nof the form ˆXα= (Y,√\\n1−Y2sin(αY)). These estima-\\ntors provide a mental demonstration of the anticipated be-\\nhavior of robust and non-robust deterministic restoration\\nalgorithms that strive for high perceptual quality. For an\\nestimator of this form, notice that αcontrols the tradeoff\\nbetween its perceptual quality and robustness: increasing\\nαimproves its perceptual quality but hinders its robust-\\nness. For instance, ˆXErratic (with α= 50 ) represents an er-\\nratic (non-robust) estimator with high perceptual quality. It\\n“zigzags” and fills the support of pX, which intuitively leads\\n4\\n\\nPage 4\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\n−101X(1)ˆXRobustˆXErraticˆXRobustGANˆXErraticGANˆXRobustStoGANˆXStoGAN\\n0 0.5 1\\nX(2)−101X(1)Precision=0.99\\nRecall=0.01\\n0 0.5 1\\nX(2)Precision=0.98\\nRecall=0.98\\n0 0.5 1\\nX(2)Precision=1.00\\nRecall=0.017\\n0 0.5 1\\nX(2)Precision=1.00\\nRecall=0.224\\n0 0.5 1\\nX(2)Precision=0.95\\nRecall=0.99\\n0 0.5 1\\nX(2)Precision=0.98\\nRecall=0.98\\nFigure 3. An illustration on a toy restoration problem of the tradeoff between robustness and perceptual quality for deterministic restoration\\nalgorithms, as well as as a demonstration that such a tradeoff does not exist for stochastic algorithms. Each column corresponds to a\\ndifferent estimator, with the estimator’s name indicated in the title of the column. Top row: the support of the data distribution (gray\\ndisc), and the support of the output distribution of each estimator (a continuous colored line of 10,000 random samples from the output\\ndistribution of each estimator). Bottom row: 100 random samples from the data distribution (gray dots), and 100 random samples from the\\noutput distribution of each estimator (colored stars). The precision and recall (Kynk ¨a¨anniemi et al., 2019) of each estimator are computed\\nbetween 1000 random output samples from the output distribution of the estimator and 1000 random samples from the data distribution.\\nRefer to Section 4 for more details.\\nto a smaller distance between pˆXandpX.ˆXRobust (with\\nα= 1) represents a robust estimator with low perceptual\\nquality. Its output mildly changes when perturbing its input,\\nso it fills a smaller region from the support of pX. To nu-\\nmerically confirm that an increased erratic behavior results\\nin higher perceptual quality, we approximate the precision\\nand recall (Kynk ¨a¨anniemi et al., 2019) of these estimators,\\nshowing that such practical statistical distance measures can\\nbe fooled by highly erratic deterministic algorithms. For an\\nanalytical confirmation, refer to Appendix C.\\n4.1. Perceptual quality approximation\\nIn real world problems pXandpˆXare typically unknown,\\nand their statistical discrepancy is commonly approximated\\nby using finite sized sets of independently drawn sam-\\nples from both distributions (e.g., (Heusel et al., 2017;\\nKynk ¨a¨anniemi et al., 2019; Sajjadi et al., 2018)). In some\\nscenarios it would be difficult or even impossible for such a\\nstatistical distance approximation algorithm to distinguish\\nbetween the output distribution of a highly erratic deter-\\nministic algorithm and the distribution of the source data.\\nTo illustrate this, we randomly and independently sample\\n1000 points from the outputs of ˆXRobust and ˆXErratic and\\napproximate their perceptual quality via precision and re-\\ncall (Kynk ¨a¨anniemi et al., 2019) (with k= 5) and withoutusing feature projection. In the bottom row of Figure 3\\nwe present 100 random output samples of each algorithm\\n(colored stars), 100 random samples from pX(gray dots),\\nas well as the precision and recall results. As expected, all\\nthe algorithms attain almost perfect precision. For the er-\\nratic estimator ˆXErratic , a human observer might be fooled to\\nbelieve that its samples are actually drawn from pX. Indeed,\\nit attains almost perfect recall as well, and consequently\\nalmost perfect perceptual quality according to these metrics.\\nHowever, the robust algorithm ˆXRobust attains a much lower\\nrecall, and one can easily distinguish between the distribu-\\ntion of its output samples and the samples from the data\\ndistribution. This illustrates what one might expect when\\nrobustifying a deterministic estimator: its perceptual quality\\nwould be limited by a lower recall.\\nThese toy restoration algorithms are hand-crafted to visu-\\nally demonstrate our hypothesis, so let us confirm that this\\nbehavior occurs for practical estimators as well.\\n4.2. Deterministic GAN estimators\\nWe trained a neural network ˆXErraticGAN =Gθ(Y)as a\\nGAN (Goodfellow et al., 2014) to solve the aforementioned\\ntoy problem (we omit the use of θfrom now on). We evalu-\\nated the precision and recall in the same fashion as before,\\nand present the results in Figure 3. As shown, ˆXErraticGAN\\n5\\n\\nPage 5\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nis indeed erratic, which aligns with our argument that this\\nwould be the behavior of a deterministic algorithm when\\nattempting to attain high perceptual quality. I.e., ˆXErraticGAN\\nbecomes highly sensitive to small input perturbations.\\nLet us observe the effect of robustifying such an estimator.\\nThe sensitivity of a deterministic algorithm G(Y)atY=y\\ncan be measured by\\nrG,ϵ(y) = max\\nδ:∥δ∥2≤ϵ∥G(y)−G(y+δ)∥2\\n2. (2)\\nThat is, rG,ϵ(y)is the extent to which a small input pertur-\\nbation of yleads to a change in the output. From here, we\\ncan measure the robustness of a deterministic estimator by\\naveraging rG,ϵ(y)for all y’s, leading to\\nRG,ϵ=E[rG,ϵ(Y)]. (3)\\nIn Figure 3 we present an additional GAN based algorithm\\nˆXRobustGAN , which was trained with RG,ϵas a regularizer\\n(refer to Appendix E.1 for full training details of these es-\\ntimators). As expected, ˆXRobustGAN is a much more stable\\nalgorithm, but has a lower perceptual quality (lower recall).\\nAs hypothesized, ˆXErraticGAN attains a higher recall than\\nˆXRobustGAN , which can also be confirmed visually as it re-\\nsults in a more erratic behavior and passes through more\\nregions in Supp(pX). We therefore confirm again that the\\nrobustness of a deterministic estimator should hinder its\\nperceptual quality (and more specifically, its recall). These\\nexperiments demonstrate again that robustness of determin-\\nistic estimators comes at the cost of lower perceptual quality.\\n5. Robustness of stochastic estimators\\nDeep-learning based recovery algorithms are known to be\\nsensitive to miniature and visually unnoticeable input per-\\nturbations, e.g. in single-image super-resolution (Choi et al.,\\n2019; 2021; 2020; Yue et al., 2021), deblurring (Gandikota\\net al., 2022), rain removal (Yu et al., 2022), and denois-\\ning (Yan et al., 2022). Studying the stability of image\\nrestoration methods is important and sometimes critical (e.g.\\nin medical imaging for diagnosis), as only robust algorithms\\nare able to provide trustworthy estimations. Interestingly,\\nto the best of our knowledge, all the existing publications\\nthat discuss robustness in image restoration only consider\\ndeterministic solutions.\\nTo discuss the robustness of an arbitrary (not necessarily\\ndeterministic) estimator, we first need to generalize the no-\\ntion of robustness to the stochastic case. We extend Equa-\\ntion (3) by thinking of robustness as the maximal deviation\\ninpˆX|Y(·|y)that can occur due to a small change in y.\\nFormally, we define the sensitivity of a possibly stochastic\\nestimator ˆXatY=yby\\nrˆX,ϵ(y) = max\\nδ:∥δ∥2≤ϵW2\\n2(pˆX|Y(·|y), pˆX|Y(·|y+δ)),(4)where W2is the Wasserstein-2 distance between distribu-\\ntions. As before, we define the overall robustness of ˆX\\nby\\nRˆX,ϵ=Eh\\nrˆX,ϵ(Y)i\\n. (5)\\nTo see why Equation (5) serves as a natural extension\\nof Equation (3), we show that both of these definitions are\\nequivalent when ˆXis a deterministic estimator. Indeed, if\\nˆX=G(Y)for some deterministic function G,pˆX|Y(·|y)\\nis a delta function for any y, so the W2distance in rˆX(y)\\nmeasures the deviation between two Dirac measures and\\ntherefore becomes a simple L2norm between two vectors,\\ni.e.,W2(pˆX|Y(·|y), pˆX|Y(·|y+δ)) =∥G(y)−G(y+δ)∥2.\\nPractically, measuring the Wasserstein-2 distance between\\ndistributions, and not to mention minimizing it, is a highly\\ndifficult task. We therefore offer an alternative in the case\\nwhere the estimator is a neural network and the stochasticity\\nis acquired by using an input random seed (as done in all\\nGANs). Let ˆX=G(Y, Z)be a neural network, where Yis\\nthe input and Zis some random seed that follows any type\\nof distribution. We propose to measure the sensitivity of ˆX\\natY=yby considering its average sensitivity over random\\ndraws of Z, i.e.,\\n˜rˆX,ϵ(y) = max\\nδ:∥δ∥2≤ϵE\\x02\\n∥G(y, Z)−G(y+δ, Z)∥2\\n2\\x03\\n.(6)\\nIn words, Equation (6) measures the extent to which a small\\ninput perturbation changes the output with the same random\\nseed, averaged over many seeds. Finally, we approximate\\nthe overall robustness of ˆXvia\\n˜RˆX,ϵ=Eh\\n˜rˆX,ϵ(Y)i\\n. (7)\\nObserve that here as well we naturally extend the definition\\nof robustness for deterministic estimators. As we move\\nfrom a stochastic to a deterministic algorithm, the variance\\nof the seed Zdrops to zero, and the two definitions coincide.\\nMoreover, this is a rational approximation method for the\\nstochastic case since Equation (7) upper bounds Equation (5)\\n(see proof in Appendix D). Hence, minimizing Equation (7)\\nforces Equation (5) to also minimize.\\nTo illustrate that stochastic algorithms can simultaneously\\nbe robust and attain high perceptual quality, we trained a\\nneural network G(Y, Z)to solve the toy problem presented\\nin Section 4, where Z∼ N(0, I)is an input random seed\\nthat allows the outputs to vary for each input Y. As be-\\nfore, we trained two consistent algorithms: ˆXStoGAN and\\nˆXRobustStoGAN , where the former is trained solely with a\\nGAN loss, and the latter is also regularized to be robust us-\\ning Equation (7) (see Appendix E.1 for full training details).\\nFollowing a similar procedure to Section 4.2, we randomly\\nsample 1000 outputs from each estimator (by sampling 1000\\n6\\n\\nPage 6\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nrandom inputs and coupling each input with one random\\nseed) and evaluate precision and recall. Unsurprisingly,\\nboth ˆXStoGAN andˆXRobustStoGAN lead to precision and recall\\nscores above 0.95, which confirms our hypothesis that a con-\\nsistent stochastic algorithm can maintain high perceptual\\nquality even when it is robust to input adversarial attacks.\\nIt is important to note that the whole discussion on robust\\nrestoration algorithms with high perceptual quality is rel-\\nevant only when assuming that a minor perturbation in y\\ndoes not lead to a large change in the posterior distribution\\npX|Y(·|y)when dealing with natural images. As discussed\\nin Section 4, a consistent deterministic estimator with high\\nperceptual quality attempts to become a posterior sampler by\\nbehaving erratically, and thus we propose to use stochastic\\nestimators instead (such as a posterior sampler). See Ap-\\npendix B for more details on this subject.\\n6. Experiments on natural images\\n6.1. Demonstrations with GANs\\nWe train several types of GAN-based restoration algorithms\\nto solve the image inpainting and super resolution tasks\\n(see Appendix F for a discussion on our choice of using\\nGANs for the following demonstrations). In all the exper-\\niments we use a U-Net architecture (Ronneberger et al.,\\n2015) as our estimator, which we denote by G(Y, Z). For\\nthe stochastic algorithms Z∼ N (0, I)is a random input\\nseed that allows their outputs to vary for each Y, while for\\nthe deterministic ones we fix Z= 0. We use the same\\narchitecture for the stochastic and deterministic algorithms\\nto ensure that it does not impair the evaluation. All the algo-\\nrithms are enforced to produce perfectly consistent restora-\\ntions. The optimization task in all of the experiments is\\na weighted sum of two objectives: LGAN andLR. Here,\\nLGAN is a non-saturating generative adversarial training\\nloss (Goodfellow et al., 2014) combined with R1critic reg-\\nularization (Mescheder et al., 2018), where the critic is the\\nsame ResNet architecture as in (Mescheder et al., 2018).\\nOptimizing such a loss would drive pˆXto be as close as\\npossible to pX, and due to the consistency enforcement, a\\nposterior sampler is the only optimal solution for this task\\n(Theorem 3.1). Note that the critic’s objective is to distin-\\nguish between samples from pˆXandpXwithout taking Y\\ninto account. The term LRis a loss that drives the restora-\\ntion algorithm to be robust to input adversarial attacks. It is\\nequal to Equation (7), where Zis zero for the deterministic\\nalgorithms. In practice, we perform 5 Adam (Kingma & Ba,\\n2014) optimization steps to approximate the attack δ∗on\\neach input y, and for the stochastic algorithms we perform\\nthe average in Equation (6) over 10 random seeds for each\\ny. The final training objective is\\nLGAN +λRLR, (8)Table 1. Quantitative evaluation of the CelebA image inpainting\\nalgorithms described in Section 6.1.1. Robstifying the determin-\\nistic restoration algorithm significantly deteriorates its recall and\\nFID performance. Doing so for the stochastic algorithm only\\nslightly hinders its performance (with the same AI-PSNR), while\\nalso improving its output variability (high per-pixel std). Refer\\nto Section 6.1.2 for further analysis of these results.\\nStochastic Deterministic\\nMetric Erratic Robust Erratic Robust\\nFID↓14.10 19.27 14.37 39.09\\nPrecision↑0.670 0.634 0.670 0.533\\nRecall↑0.388 0.268 0.382 0.022\\nPer-pixel std↑0.007 0.105 0 0\\nRobustness↑6.884 26.19 3.544 23.69\\nAI-PSNR 34.47 32.95 34.18 32.98\\nwhere λRcontrols the level of the algorithm’s robustness.\\nComplementary training details are provided in the follow-\\ning sections and in Appendix E.2.\\n6.1.1. E XPERIMENTAL SETUP\\nInpainting: We perform several experiments on the image\\ninpainting task, in which some pixels of a high quality im-\\nage are masked and a restoration algorithm estimates their\\nvalues. We assume that the locations of the masked pixels\\nare fixed and known. In all of our experiments, we mask the\\nupper3\\n4part of the image, and leave the remaining bottom\\npixels untouched. We use the CelebA data set (Liu et al.,\\n2015) for the experiments in this task. Consistency is en-\\nforced by replacing the bottom1\\n4part of the output with\\nthat of the input, a typical way to enforce consistency in\\nimage inpainting (Saharia et al., 2021; Yu et al., 2018a;b;\\nYi et al., 2020; Zhao et al., 2021). We train several consis-\\ntent restoration algorithms by optimizing Equation (8): two\\ndeterministic and two stochastic models, where one of each\\nis trained with λR= 0and the other with λR= 500 . We\\nrefer to the algorithms trained with λR= 0aserratic , and\\nto the others as robust . We choose ϵin Equation (7) so that\\nPSNR (y+δ∗, y)≥32.9dBfor any y(so that δ∗leads to a\\nbarely noticeable change in y). We refer to this quantity as\\ntheadversarial input PSNR (AI-PSNR).\\nSuper resolution: We train the same types of algorithms as\\nbefore (erratic & robust, deterministic & stochastic), but this\\ntime we solve the super resolution task. The degradation we\\nconsider is a plain averaging with scaling factors of 4×,8×,\\nand16×. The training objective and the used architectures\\nremain the same. Consistency is enforced with CEM (Bahat\\n& Michaeli, 2020). Unlike in the inpainting task, this time\\nthe dimensionality of the input is different than that of the\\noutput. Since our estimator is a neural network with input\\n7\\n\\nPage 7\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nand output of the same size, we feed to it an upsampled\\nversion of the low-resolution image, using nearest-neighbor\\ninterpolation. Moreover, we train the models on CelebA,\\nas well as on the 64×64version of ImageNet (Chrabaszcz\\net al., 2017).\\nPerformance metrics: For the inpainting algorithms, we\\nreport in Table 1 the perceptual quality performance ac-\\ncording to FID (Heusel et al., 2017), precision, and re-\\ncall (Kynk ¨a¨anniemi et al., 2019) (with k= 3), and present\\nseveral outputs produced by the algorithms in Figure 1. We\\nalso demonstrate the quality and the extent of the output\\nvariation of the stochastic models by showing four output\\nsamples for each input. The perceptual quality metrics are\\ncomputed by considering the training set as the real samples,\\nand the algorithms’ outputs on the validation set as the fake\\nsamples. Moreover, we report the robustness performance\\nof each algorithm according to\\nE[PSNR (G(Y, Z), G(Y+δ∗(Y), Z)], (9)\\nwhere the average is computed over the entire validation set\\nandδ∗(y)is the solution of Equation (6) for each y, and is\\nacquired in the same fashion as in the training stage. Lastly,\\nwe report the per-pixel standard deviation of each algorithm\\nover 32 restored samples (for the same input), averaged\\nacross all the output pixels and over the entire validation\\nset. This measures the average variation of the output pixels\\nfor all the inputs in the validation data, i.e., a higher value\\ncorresponds to a more diverse output space, per input, on\\naverage. In Figure 4 we report these performance metrics\\nfor the super resolution algorithms as well. Please refer\\nto Appendix E.2 for complementary training details.\\n6.1.2. A NALYSIS OF THE RESULTS\\nInpainting: The erratic deterministic algorithm is competi-\\ntive with the stochastic methods in terms of FID (Table 1).\\nHowever, while both robust algorithms attain the same level\\nof robustness (and for the same AI-PSNR), the determinis-\\ntic one suffers from a significant deterioration in FID and\\nthe stochastic one does not. This can be confirmed visu-\\nally in Figure 1 as well. As the only difference between\\nthe robust algorithms is the random noise injection (same\\nmodel, same loss, etc.), this result supports our hypothesis\\nthat stochastic models can overcome the trade-off between\\nrobustness and perceptual quality of deterministic mappings.\\nAnother interesting outcome is that the erratic stochastic\\nalgorithm produces virtually zero output diversity per input,\\nwhile the robust stochastic algorithm maintains meaningful\\noutput variation. This can be confirmed by the naked eye\\nwhen observing the randomly sampled outputs in Figure 1\\n(the robust algorithm creates several types of hair, genders,\\netc. for the same input), and by the higher per-pixel standard\\ndeviation. These results yield several insights: 1) Since the0.000.501.00Precision↑CelebA ImageNet\\n0.000.501.00Recall↑\\n10.020.030.0FID↓\\n4070100\\n0.000.050.100.15Per-pixel std↑\\n48 16\\nScaling factor12.024.036.0Robustness↑\\n48 16\\nScaling factor\\nErratic sto.\\nRobust sto.Erratic det.\\nRobust det.\\nFigure 4. Quantitative evaluation of the super resolution algorithms\\ndescribed in Section 6.1.1. AI-PSNR is equal to 34dB for all al-\\ngorithms. The anticipated link between robustness and perceptual\\nquality is revealed again: The robust deterministic models achieve\\nthe lowest perceptual quality for all scaling factors. As the scaling\\nfactor (degradation severity) increases, we observe higher output\\nvariability only for the robust stochastic models, and a larger per-\\nceptual quality gap for the robust deterministic models.\\n8\\n\\nPage 8\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nerratic stochastic algorithm barely produces output variation,\\nit effectively behaves like a deterministic estimator. This\\nshows that the instability of a stochastic model is indica-\\ntive of conditional mode-collapse (Goodfellow et al., 2014;\\nIsola et al., 2017; Mathieu et al., 2016; Yang et al., 2019).\\n2) Apparently, in order to attain high perceptual quality, it\\nis less challenging to learn an erratic output curvature rather\\nthan to map a random input seed to meaningful, high quality\\noutput variation. 3) Enforcing robustness on a stochastic\\nmodel promotes meaningful output variation and effectively\\nalleviates the conditional mode-collapse issue. These results\\nfurther support our link between the robustness and stochas-\\nticity of a restoration algorithm, as anticipated. Indeed, we\\nobserve that the robust deterministic model suffers from a\\nvery low recall compared to the robust stochastic one.\\nSuper resolution: The first observation we make from Fig-\\nure 4 is that, as the scaling factor increases, the FID of all\\nalgorithms deteriorate. This is supposedly a result of at-\\ntempting to solve a more difficult inverse problem: higher\\nscaling factors preserve less information (the problem is\\n“more” ill-posed). Yet, we see that for the same degradation\\nseverity, the robust deterministic algorithm always attains\\nthe worst FID performance. Moreover, its FID gap with\\nthe other algorithms increases with the scaling factor, sug-\\ngesting that the tradeoff between robustness and perceptual\\nquality (for deterministic estimators) is more severe for a\\nhigher scaling factor. Intuitively, a higher scaling factor is\\nexpected to increase the size of the support of pX|Y(·|y)\\nfor any y, so it covers a larger portion of the support of pX.\\nWe therefore hypothesize that, for high scaling factors, a\\nconsistent, robust deterministic estimator would “miss” a\\nlarger portion in the support of pX, and would therefore\\nattain lower recall, just as the results show. Interestingly, we\\nsee that the precision of all algorithms and across all scaling\\nfactors remain roughly the same, showing that a restora-\\ntion algorithm can indeed output images that appear natural\\nbut still attain low perceptual quality (due to low recall).\\nLastly, we again see that the erratic stochastic model barely\\nproduces output variability, while the robust one does.\\n6.2. Robustness of SRFlow\\nPrevious work (Choi et al., 2019; 2021) hypothesize that\\nrestoration algorithms with high perceptual quality are more\\nvulnerable to adversarial attacks. This hypothesis stems\\nfrom the low robustness levels of ESRGAN (Wang et al.,\\n2018), a GAN-based, deterministic, high perceptual quality\\nalgorithm. However, such a hypothesis is limited as it is\\nbased on the evaluation of a single high perceptual quality\\nrestoration algorithm. Here we provide additional support\\nfor our claim that such an hypothesis is incomplete: it is\\nvalid only for deterministic estimators, while stochastic ones\\ncan be robust and still attain high perceptual quality.In Appendix G we evaluate the robustness of SRFlow (Lug-\\nmayr et al., 2020), a stochastic super-resolution algorithm\\nthat produces highly consistent outputs and comparable per-\\nceptual quality to ESRGAN (Wang et al., 2018). As reported\\nin Figure 8, SRFlow exhibits substantially higher robustness\\nthan ESRGAN, and comparable robustness to distortion-\\noptimized models. These findings further demonstrate the\\npotential of high perceptual quality stochastic estimators to\\nattain superior robustness compared to deterministic estima-\\ntors with comparable perceptual quality performance.\\n7. Summary\\nIn this work we ask whether stochastic estimators are better\\nthan deterministic ones, and our short answer is yes. Indeed,\\nwe proved that a posterior sampler is the only restoration\\nalgorithm with perfect consistency and perceptual quality,\\nwhich shows that a consistent deterministic algorithm can\\nnever attain perfect perceptual quality. While a determinis-\\ntic estimator can still attain high perceptual quality, it must\\nadopt an erratic output behavior in order to do so, which\\nmakes it vulnerable to adversarial attacks. Hence, our work\\nprovides a novel explanation for the existence of adversar-\\nial attacks in high perceptual quality deterministic restora-\\ntion algorithms. We expand the notion of robustness for\\nstochastic algorithms, and then show that such algorithms\\ncan significantly alleviate the tradeoff between robustness\\nand perceptual quality that exists in deterministic algorithms.\\nInterestingly, we find that robustness can be used to promote\\nmeaningful output variability in stochastic models, which\\naligns well with the theory and hypothesis developed in\\nthis paper. Our conclusion: Robust, stochastic restoration\\nalgorithms do provide better recovery.\\n8. Acknowledgments\\nThis research was partially supported by the Israel Science\\nFoundation (ISF) under Grants 335/18 and 2318/22 and by\\nthe Council For Higher Education - Planning & Budgeting\\nCommittee.\\nReferences\\nAntun, V ., Renna, F., Poon, C., Adcock, B., and Hansen,\\nA. C. On instabilities of deep learning in image recon-\\nstruction and the potential costs of ai. Proceedings of the\\nNational Academy of Sciences , 117(48):30088–30095,\\n2020.\\nBahat, Y . and Michaeli, T. Explorable super resolution. In\\nProceedings of the IEEE Conference on Computer Vision\\nand Pattern Recognition (CVPR) , June 2020.\\nBevilacqua, M., Roumy, A., Guillemot, C., and line Al-\\nberi Morel, M. Low-complexity single-image super-\\n9\\n\\nPage 9\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nresolution based on nonnegative neighbor embedding.\\nInProceedings of the British Machine Vision Conference ,\\npp. 135.1–135.10. BMV A Press, 2012. ISBN 1-901725-\\n46-4.\\nBlau, Y . and Michaeli, T. The perception-distortion tradeoff.\\nInProceedings of the IEEE Conference on Computer\\nVision and Pattern Recognition (CVPR) , June 2018.\\nChen, R., Qu, Y ., Zeng, K., Guo, J., Li, C., and Xie, Y .\\nPersistent memory residual network for single image su-\\nper resolution. In Proceedings of the IEEE Conference\\non Computer Vision and Pattern Recognition (CVPR)\\nWorkshops , June 2018.\\nChoi, J.-H., Zhang, H., Kim, J.-H., Hsieh, C.-J., and Lee, J.-\\nS. Evaluating robustness of deep image super-resolution\\nagainst adversarial attacks. In Proceedings of the IEEE\\nInternational Conference on Computer Vision (ICCV) ,\\nOctober 2019.\\nChoi, J.-H., Zhang, H., Kim, J.-H., Hsieh, C.-J., and Lee, J.-\\nS. Adversarially robust deep image super-resolution using\\nentropy regularization. In Proceedings of the Asian Con-\\nference on Computer Vision (ACCV) , November 2020.\\nChoi, J.-H., Zhang, H., Kim, J.-H., Hsieh, C.-J., and Lee,\\nJ.-S. Deep image destruction: Vulnerability of deep\\nimage-to-image models against adversarial attacks. arXiv\\npreprint arXiv:2104.15022 , 2021.\\nChrabaszcz, P., Loshchilov, I., and Hutter, F. A downsam-\\npled variant of imagenet as an alternative to the cifar\\ndatasets. arXiv preprint arXiv:1707.08819 , 2017.\\nDong, C., Loy, C. C., He, K., and Tang, X. Image super-\\nresolution using deep convolutional networks, 2015.\\nFreirich, D., Michaeli, T., and Meir, R. A theory of the\\ndistortion-perception tradeoff in wasserstein space. In\\nRanzato, M., Beygelzimer, A., Dauphin, Y ., Liang, P.,\\nand Vaughan, J. W. (eds.), Advances in Neural Informa-\\ntion Processing Systems , volume 34, pp. 25661–25672.\\nCurran Associates, Inc., 2021.\\nGalteri, L., Seidenari, L., Bertini, M., and Del Bimbo, A.\\nDeep generative adversarial compression artifact removal.\\narXiv preprint arXiv:1704.02518 , 2017.\\nGandikota, K. V ., Chandramouli, P., and Moeller, M. On\\nadversarial robustness of deep image deblurring. In\\n2022 IEEE International Conference on Image Process-\\ning (ICIP) , pp. 3161–3165, 2022.\\nGatopoulos, I., Stol, M., and Tomczak, J. M. Super-\\nresolution variational auto-encoders. 2020.Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,\\nWarde-Farley, D., Ozair, S., Courville, A., and Bengio, Y .\\nGenerative adversarial nets. In Ghahramani, Z., Welling,\\nM., Cortes, C., Lawrence, N., and Weinberger, K. (eds.),\\nAdvances in Neural Information Processing Systems , vol-\\nume 27. Curran Associates, Inc., 2014.\\nHe, K., Zhang, X., Ren, S., and Sun, J. Deep resid-\\nual learning for image recognition. arXiv preprint\\narXiv:1512.03385 , 2015.\\nHeusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and\\nHochreiter, S. Gans trained by a two time-scale update\\nrule converge to a local nash equilibrium. In Guyon, I.,\\nLuxburg, U. V ., Bengio, S., Wallach, H., Fergus, R., Vish-\\nwanathan, S., and Garnett, R. (eds.), Advances in Neural\\nInformation Processing Systems , volume 30. Curran As-\\nsociates, Inc., 2017.\\nIoffe, S. and Szegedy, C. Batch normalization: Accelerating\\ndeep network training by reducing internal covariate shift.\\narXiv preprint arXiv:1502.03167 , 2015.\\nIsola, P., Zhu, J.-Y ., Zhou, T., and Efros, A. A. Image-to-\\nimage translation with conditional adversarial networks.\\nInProceedings of the IEEE Conference on Computer\\nVision and Pattern Recognition , July 2017.\\nJo, Y ., Yang, S., and Kim, S. J. Srflow-da: Super-resolution\\nusing normalizing flow with deep convolutional block.\\nInProceedings of the IEEE Conference on Computer\\nVision and Pattern Recognition (CVPR) Workshops , pp.\\n364–372, June 2021.\\nKadkhodaie, Z. and Simoncelli, E. Stochastic solutions\\nfor linear inverse problems using the prior implicit in\\na denoiser. In Ranzato, M., Beygelzimer, A., Dauphin,\\nY ., Liang, P., and Vaughan, J. W. (eds.), Advances in\\nNeural Information Processing Systems , volume 34, pp.\\n13242–13254. Curran Associates, Inc., 2021.\\nKastryulin, S., Zakirov, D., and Prokopenko, D. PyTorch\\nImage Quality: Metrics and measure for image quality\\nassessment, 2019. Open-source software available at\\nhttps://github.com/photosynthesis-team/piq.\\nKawar, B., Vaksman, G., and Elad, M. Stochastic image\\ndenoising by sampling from the posterior distribution. In\\nProceedings of the IEEE/CVF International Conference\\non Computer Vision (ICCV) Workshops , pp. 1866–1875,\\nOctober 2021a.\\nKawar, B., Vaksman, G., and Elad, M. Snips: Solving noisy\\ninverse problems stochastically. In Ranzato, M., Beygelz-\\nimer, A., Dauphin, Y ., Liang, P., and Vaughan, J. W.\\n(eds.), Advances in Neural Information Processing Sys-\\ntems, volume 34, pp. 21757–21769. Curran Associates,\\nInc., 2021b.\\n10\\n\\nPage 10\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nKawar, B., Elad, M., Ermon, S., and Song, J. Denoising\\ndiffusion restoration models. In Advances in Neural In-\\nformation Processing Systems , 2022.\\nKim, J., Lee, J. K., and Lee, K. M. Accurate image super-\\nresolution using very deep convolutional networks. arXiv\\npreprint arXiv:1511.04587 , 2015.\\nKingma, D. P. and Ba, J. Adam: A method for stochastic\\noptimization. arXiv preprint arXiv:1412.6980 , 2014.\\nKurakin, A., Goodfellow, I. J., and Bengio, S. Adversarial\\nmachine learning at scale. In International Conference\\non Learning Representations (ICLR) , 2017.\\nKynk ¨a¨anniemi, T., Karras, T., Laine, S., Lehtinen, J., and\\nAila, T. Improved precision and recall metric for assess-\\ning generative models. In Wallach, H., Larochelle, H.,\\nBeygelzimer, A., d 'Alch ´e-Buc, F., Fox, E., and Garnett,\\nR. (eds.), Advances in Neural Information Processing\\nSystems , volume 32. Curran Associates, Inc., 2019.\\nLedig, C., Theis, L., Huszar, F., Caballero, J., Cunningham,\\nA., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z.,\\nand Shi, W. Photo-realistic single image super-resolution\\nusing a generative adversarial network. In Proceedings\\nof the IEEE Conference on Computer Vision and Pattern\\nRecognition (CVPR) , July 2017.\\nLiu, Z., Luo, P., Wang, X., and Tang, X. Deep learning face\\nattributes in the wild. In Proceedings of International\\nConference on Computer Vision (ICCV) , December 2015.\\nLiu, Z.-S., Siu, W.-C., and Chan, Y .-L. Photo-realistic im-\\nage super-resolution via variational autoencoders. IEEE\\nTransactions on Circuits and Systems for Video Technol-\\nogy, 31:1351–1365, 4 2021a. ISSN 1051-8215.\\nLiu, Z.-S., Siu, W.-C., and Wang, L.-W. Variational au-\\ntoencoder for reference based image super-resolution. pp.\\n516–525. IEEE, 6 2021b. ISBN 978-1-6654-4899-4.\\nLugmayr, A., Danelljan, M., Van Gool, L., and Timofte,\\nR. Srflow: Learning the super-resolution space with\\nnormalizing flow. In ECCV , 2020.\\nLugmayr, A., Danelljan, M., and Timofte, R. Ntire 2021\\nlearning the super-resolution space challenge. In Pro-\\nceedings of the IEEE Conference on Computer Vision\\nand Pattern Recognition (CVPR) Workshops , pp. 596–\\n612, June 2021.\\nLugmayr, A., Danelljan, M., Timofte, R., Kim, K.-w., Kim,\\nY ., Lee, J.-y., Li, Z., Pan, J., Shim, D., Song, K.-U., Tang,\\nJ., Wang, C., and Zhao, Z. Ntire 2022 challenge on\\nlearning the super-resolution space. In Proceedings of\\nthe IEEE Conference on Computer Vision and Pattern\\nRecognition (CVPR) Workshops , pp. 786–797, June 2022.Martin, D., Fowlkes, C., Tal, D., and Malik, J. A database\\nof human segmented natural images and its application\\nto evaluating segmentation algorithms and measuring\\necological statistics. In Proceedings of the IEEE Interna-\\ntional Conference on Computer Vision (ICCV) , volume 2,\\npp. 416–423 vol.2, 2001.\\nMathieu, M., Couprie, C., and LeCun, Y . Deep multi-\\nscale video prediction beyond mean square error. arXiv\\npreprint arXiv:1511.05440 , 2016.\\nMescheder, L., Nowozin, S., and Geiger, A. Which training\\nmethods for gans do actually converge? In International\\nConference on Machine Learning (ICML) , 2018.\\nOhayon, G., Adrai, T., Vaksman, G., Elad, M., and Milan-\\nfar, P. High perceptual quality image denoising with a\\nposterior sampling cgan. In Proceedings of the IEEE\\nInternational Conference on Computer Vision (ICCV)\\nWorkshops , pp. 1805–1813, October 2021.\\nRaj, A., Bresler, Y ., and Li, B. Improving robustness of deep-\\nlearning-based image reconstruction. In III, H. D. and\\nSingh, A. (eds.), Proceedings of the 37th International\\nConference on Machine Learning , volume 119 of Pro-\\nceedings of Machine Learning Research , pp. 7932–7942.\\nPMLR, 13–18 Jul 2020.\\nRonneberger, O., Fischer, P., and Brox, T. U-net: Con-\\nvolutional networks for biomedical image segmentation.\\narXiv preprint arXiv:1505.04597 , 2015.\\nSaharia, C., Chan, W., Chang, H., Lee, C. A., Ho, J.,\\nSalimans, T., Fleet, D. J., and Norouzi, M. Palette:\\nImage-to-image diffusion models. arXiv preprint\\narXiv:2111.05826 , 2021.\\nSajjadi, M. S. M., Bachem, O., Lucic, M., Bousquet, O.,\\nand Gelly, S. Assessing generative models via precision\\nand recall. In Bengio, S., Wallach, H., Larochelle, H.,\\nGrauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.),\\nAdvances in Neural Information Processing Systems , vol-\\nume 31. Curran Associates, Inc., 2018.\\nShi, W., Caballero, J., Husz ´ar, F., Totz, J., Aitken, A. P.,\\nBishop, R., Rueckert, D., and Wang, Z. Real-time sin-\\ngle image and video super-resolution using an efficient\\nsub-pixel convolutional neural network. arXiv preprint\\narXiv:1609.05158 , 2016.\\nSong, Y . and Ermon, S. Generative modeling by estimat-\\ning gradients of the data distribution. In Wallach, H.,\\nLarochelle, H., Beygelzimer, A., d 'Alch ´e-Buc, F., Fox, E.,\\nand Garnett, R. (eds.), Advances in Neural Information\\nProcessing Systems , volume 32. Curran Associates, Inc.,\\n2019.\\n11\\n\\nPage 11\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nSzegedy, C., Vanhoucke, V ., Ioffe, S., Shlens, J., and Wojna,\\nZ. Rethinking the inception architecture for computer\\nvision. arXiv preprint arXiv:1512.00567 , 2015.\\nWang, X., Yu, K., Wu, S., Gu, J., Liu, Y ., Dong, C., Qiao, Y .,\\nand Change Loy, C. Esrgan: Enhanced super-resolution\\ngenerative adversarial networks. In Proceedings of the\\nEuropean Conference on Computer Vision (ECCV) Work-\\nshops , September 2018.\\nYan, H., Zhang, J., Feng, J., Sugiyama, M., and Tan, V . Y . F.\\nTowards adversarially robust deep image denoising. In\\nRaedt, L. D. (ed.), Proceedings of the Thirty-First Interna-\\ntional Joint Conference on Artificial Intelligence, IJCAI-\\n22, pp. 1516–1522. International Joint Conferences on\\nArtificial Intelligence Organization, 7 2022. Main Track.\\nYang, D. et al. Diversity-sensitive conditional generative\\nadversarial networks. In International Conference on\\nLearning Representations (ICLR) , 2019.\\nYi, Z., Tang, Q., Azizi, S., Jang, D., and Xu, Z. Contex-\\ntual residual aggregation for ultra high-resolution image\\ninpainting. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition (CVPR) , June\\n2020.\\nYu, J., Lin, Z., Yang, J., Shen, X., Lu, X., and Huang, T. S.\\nGenerative image inpainting with contextual attention.\\narXiv preprint arXiv:1801.07892 , 2018a.\\nYu, J., Lin, Z., Yang, J., Shen, X., Lu, X., and Huang, T. S.\\nFree-form image inpainting with gated convolution. arXiv\\npreprint arXiv:1806.03589 , 2018b.\\nYu, Y ., Yang, W., Tan, Y .-P., and Kot, A. C. Towards robust\\nrain removal against adversarial attacks: A comprehen-\\nsive benchmark analysis and beyond. arXiv preprint\\narXiv:2203.16931 , 2022.\\nYue, J., Li, H., Wei, P., Li, G., and Lin, L. Robust real-world\\nimage super-resolution against adversarial attacks. In\\nProceedings of the 29th ACM International Conference\\non Multimedia , MM ’21, pp. 5148–5157, New York, NY ,\\nUSA, 2021. Association for Computing Machinery. ISBN\\n9781450386517.\\nZeyde, R., Elad, M., and Protter, M. On single image scale-\\nup using sparse-representations. In Proceedings of the\\n7th International Conference on Curves and Surfaces ,\\npp. 711–730, Berlin, Heidelberg, 2010. Springer-Verlag.\\nISBN 9783642274121.\\nZhao, S., Cui, J., Sheng, Y ., Dong, Y ., Liang, X., Chang,\\nE. I., and Xu, Y . Large scale image completion via co-\\nmodulated generative adversarial networks. In Interna-\\ntional Conference on Learning Representations (ICLR) ,\\n2021.\\n12\\n\\nPage 12\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nA. Proof of Theorem 3.1\\nTheorem 3.1. For a deterministic degradation, y=D(x), an estimator ˆXis perfectly consistent ( pY|X=pY|ˆX) and\\nachieves perfect perceptual quality ( pˆX=pX) if and only if it is the posterior sampler pˆX|Y=pX|Y.\\nProof. First, note that D(ˆX) =D(X)if and only if pY|ˆX=pY|X. Assume that pˆX|Y=pX|Y. Then,\\npˆX(x) =Z\\nypˆX|Y(x|y)pY(y)dy=Z\\nypX|Y(x|y)pY(y)dy=pX(x),\\nand\\npY|ˆX(y|x) =pˆX|Y(x|y)pY(y)\\npˆX(x)=pX|Y(x|y)pY(y)\\npX(x)=pY|X(y|x).\\nIn the other direction, assume that pˆX=pXandpY|ˆX=pY|X. Then,\\npˆX|Y(x|y) =pY|ˆX(y|x)pˆX(x)\\npY(y)=pY|X(y|x)pX(x)\\npY(y)=pX|Y(x|y),\\nconcluding the proof.\\nB. Further discussion on deterministic estimators\\nIn this section we expand on the topics discussed in Section 4 and Section 5.\\nB.1. A tradeoff between precision and recall for continuous, consistent deterministic estimators\\n−0.50.00.5X(1)Supp( pX)ˆX1\\nPrecision=0.95\\nRecall=0.71ˆX2\\nPrecision=0.77\\nRecall=0.94\\n−1.0−0.5 0.0 0.5 1.0\\nX(2)−0.50.00.5X(1)\\n−1.0−0.5 0.0 0.5 1.0\\nX(2)−1.0−0.5 0.0 0.5 1.0\\nX(2)\\nFigure 5. Mental illustration of a tradeoff between precision and recall for consistent, high perceptual quality, continuous deterministic\\nestimators. In the top row we show the support of the data distribution and of the distribution of each estimator’s outputs. In the bottom\\nrow we show 100 random samples from these distributions. ˆX1avoids the forbidden region (the middle empty ellipse which is not part of\\nSupp(pX)), and therefore attains almost perfect precision with impaired recall. ˆX2passes through the forbidden region in order to attain\\nhigher recall, but as a result compromises on precision since it generates outputs that are not in the data distribution.\\nLetX= (X(1), X(2))be a two dimensional random variable supported on the set of all points between two concentric\\nellipses, as shown in Figure 5. The task is to estimate Xgiven Y=X(1)with perfect consistency. Notice that, different\\n13\\n\\nPage 13\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nfrom the example in Section 4, now there is a “hole” in the support of pX. In Figure 5 we present two hypothetical estimators\\nthat are consistent and continuous (these estimators are handcrafted for the purpose of this demonstration). Observe that due\\nto the hole in pX, a continuous, deterministic estimator, regardless of how erratic it is, can never approach having perfect\\nperceptual quality (unlike the two examples in Appendix C and Section 4). Such an estimator would always have to pass\\nthrough the central empty ellipse region, which is not part of Supp(pX), in order to produce outputs from both sides of\\nSupp(pX). Interestingly, this example reveals a tradeoff between precision and recall for such continuous deterministic\\nestimators. To demonstrate this, let us assume that the data distribution is uniform over its support (the set of points\\nbetween the two concentric ellipses). We randomly sample 1000 points from each distribution, and compute precision\\nand recall as in Section 4.1. As the results show (Figure 5), ˆX1, the estimator that does not pass through the forbidden\\nregion, compromises on recall in order to attain higher precision. ˆX2decides to pass through the forbidden region in order\\nto generate samples from the left side of the ellipse, which results in lower precision and higher recall.\\nNotice that the situation described above has nothing to do with robustness, and occurs even for erratic, non-robust\\ndeterministic estimators. Moreover, this tradeoff does not exist for stochastic estimators (Theorem 3.1).\\nB.2. A note on the MMSE and MAP estimators\\nIn Section 5 we note that the discussion on robust estimators with high perceptual quality is only relevant when assuming\\nthat a posterior sampler is robust, i.e., when a small change in ydoes not lead to an unreasonable change in the distribution\\npX|Y(·|y). In such a case, we expect that both the MMSE estimator E[X|Y]and the Maximum A Posteriori (MAP) estimator\\nmax xpX|Y(x|Y)would also be robust, since the mean and the maximum of pX|Y(·|y)cannot significantly deviate when a\\nsmall perturbation is added to y.\\nC. Concrete mathematical example\\nFigure 6. An illustration of Supp(pˆX)(zigzag line) and the mapping Kf(X(1), X(2))(arrow lines), where ˆX= (X(1), Gf(X(1)))is\\nthe estimator from Appendix C and the mapping Kf(X(1), X(2))maps each point (X(1), X(2))onto the zigzag in a horizontal fashion,\\nas illustrated in the figure.\\nWe provide a concrete toy example which shows that the perceptual index (according to the W2distance) of a consistent\\ndeterministic estimator can be arbitrarily minimized by making the estimator more erratic. Let X= (X(1), X(2))be a two\\ndimensional random variable, where X(1), X(2)∼U(0,1), and X(1), X(2)are statistically independent. Let Y=X(1),\\nandˆX= (Y, G f(Y))be a consistent, deterministic estimator, where Gf(y) =1\\nπarccos (cos (2 πfy))andf∈N. Our goal\\nis to show that\\nW2(pX, pˆX)−→\\nf→∞0. (10)\\nWe prove this by considering the Monge formulation of the W2distance, i.e.,\\nW2\\n2(pX, pˆX) = inf\\nTE[∥X−T(X)∥2\\n2]s.t. T (X)∼pˆX, (11)\\n14\\n\\nPage 14\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nwhich is true since pXis absolutely continuous. Let\\nKf(x1, x2) =1\\n2f \\n⌊2fx1⌋+(\\n1−x2mod(⌊2fx1⌋,2) = 1\\nx2 mod(⌊2fx1⌋,2) = 0!\\n, (12)\\nT0(X) = (Kf(X(1), X(2)), X(2)). (13)\\nOne can show that T0(X)∼pˆX(see Figure 6 for intuition), so T0satisfies the constraint in Equation (11) and therefore\\nW2\\n2(pX, pˆX)≤E[∥X−T0(X)∥2\\n2]. (14)\\nMoreover, ∀x1, x2∈[0,1]we have\\nlim\\nf→∞(x1−1\\n2f(⌊2fx1⌋ −x2))2= 0, (15)\\nlim\\nf→∞(x1−1\\n2f(⌊2fx1⌋ −1 +x2))2= 0, (16)\\nso\\nlim\\nf→∞(x1−Kf(x1, x2))2= 0. (17)\\nSince both X(1), Kf(X(1), X(2))∼U[0,1], we have that P((X(1)−Kf(X(1), X(2)))2≤4) = 1 . Hence, from the\\ndominated convergence theorem (DCT) we have\\nW2\\n2(pX, pˆX)≤lim\\nf→∞E[∥X−T0(X)∥2\\n2] = lim\\nf→∞Z\\n[0,1]2(x1−Kf(x1, x2))2pX(x1, x2)dx1dx2 (18)\\n=Z\\n[0,1]2lim\\nf→∞(x1−Kf(x1, x2))2pX(x1, x2)dx1dx2= 0. (19)\\nWe have shown that the perceptual index of the estimator ˆXcan be arbitrarily minimized (by taking larger values of f).\\nD. Proof that Equation (7) upper bounds Equation (5)\\nOur goal is to show that\\nRˆX,ϵ≤˜RˆX,ϵ. (20)\\nLetˆX=G(Y, Z)for some random variables Y, Z, and let\\nδ∗= arg max\\nδ:∥δ∥2≤ϵW2\\n2(pˆX|Y(·|y), pˆX|Y(·|y+δ)). (21)\\nThen, for any y\\nrˆX,ϵ(y) =W2\\n2(pˆX|Y(·|y), pˆX|Y(·|y+δ∗)). (22)\\nNote that the W2distance between pˆX|Y(·|y)andpˆX|Y(·|y+δ∗)is essentially the distance between the distributions of\\nthe random variables G(y, Z)andG(y+δ∗, Z). Since the MSE between two random variables upper bounds their W2\\n2\\ndistance, we have\\nrˆX,ϵ(y)≤E[∥G(y, Z)−G(y+δ∗, Z)∥2\\n2]. (23)\\nBy the definition of ˜rˆX,ϵwe have\\nE[∥G(y, Z)−G(y+δ∗, Z)∥2\\n2]≤˜rˆX,ϵ(y), (24)\\nsorˆX,ϵ(y)≤˜rˆX,ϵ(y), and since this is true for any y, we conclude that\\nRˆX,ϵ=Eh\\nrˆX,ϵ(Y)i\\n≤Eh\\n˜rˆX,ϵ(Y)i\\n=˜RˆX,ϵ. (25)\\n15\\n\\nPage 15\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nE. Complementary training details\\nE.1. Toy GAN experiments\\nThe sizes of the training and validation sets are 100,000 and 10,000, respectively, both of which are random, independent\\nsamples from the toy distribution described in Section 4. In all experiments the estimator’s and critic’s architecture is\\nthe simple fully connected network described in Table 2. Notice that the estimator outputs only one value (the estimate\\nofX(2)) as the value of X(1)is known. The output and the input are being concatenated to result in an output of size 2,\\nwhich is the final estimate. For the stochastic estimators ˆXStoGAN andˆXErraticStoGAN one of the inputs is Yand the other is\\nZ∼U[0,1]. For the deterministic estimators we simply fix Z= 0, like we do in the experiments on natural images. The\\nloss we use is the exact same one we use for natural images, but with a gradient penalty coefficient of 10.0, and λR= 0.1\\nfor the robust estimators (both the deterministic and the stochastic). During training, we alternate between one training step\\nfor the estimator and one step for the critic, where each is trained for a total of 20,000steps. To optimize the parameters\\nof the networks we use the Adam optimizer with (β1, β2) = (0 ,0.9)and a learning rate of 10−4.ϵin the computation\\nof Equation (7) is set to 10−3in all experiments. For the stochastic estimator, we perform the average in Equation (6) over\\n50 realizations of Z. Finding the adversarial attack on each input in done by using the Adam optimizer for 4 steps, with\\n(β1, β2) = (0 .9,0.999) and a learning rate of 10−4. In Table 3 we report the robustness values of all toy GAN estimators.\\nTable 2. The architecture of both the estimator and critic in all toy GAN experiments.\\nLayer Output size Filter\\nFully Connected 512 2→512\\nReLU 512 -\\nFully Connected 512 512→512\\nReLU 512 -\\nFully Connected 512 512→512\\nReLU 512 -\\nFully Connected 512 512→512\\nReLU 512 -\\nFully Connected 512 512→1\\nTable 3. Robustness of the toy GAN estimators from Section 4.2 and Section 5.\\nEstimator Robustness:q\\n˜RˆX,ϵ(·10−3)(higher is better) ϵ(·10−3)\\nˆXErraticGAN 3.62 1\\nˆXRobustGAN 0.77 1\\nˆXStoErraticGAN 0.13 1\\nˆXStoRobustGAN 0.51 1\\nE.2. Experiments on natural images\\nE.2.1. N EURAL NETWORK ARCHITECTURES\\nIn all the experiments the estimator is a U-Net architecture (Ronneberger et al., 2015) (receiving YandZas inputs), and the\\ncritic is a ResNet model (He et al., 2015) with a similar structure to the one described in (Mescheder et al., 2018). Full\\ndetails of the architectures are disclosed in Figure 7 and Table 4. While the chosen GAN architecture for the deterministic\\nand stochastic estimators could have been further improved, we chose the structure described herein, as it provides good\\nquality outcomes and is relatively easy to train. We believe that, while improving the GAN training and architecture may\\nboost performance, it would not change the interplay we exposed between deterministic and stochastic restoration methods.\\nE.2.2. O PTIMIZATION SETTINGS\\nWe alternate between optimizing the estimator and the critic (one step for each model at a time), performing a total of 1.2M\\nsteps for each model. At the estimator’s optimization step we also perform an “inner” optimization procedure that finds\\n16\\n\\nPage 16\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nDoubleConv\\nBlockDown Block 1  \\nUp Block 4  Down Block 2  Down Block 3  Down Block 4  \\nCat\\nConv2D  Up Block 3  Up Block 2  Up Block 1  Cat Cat Cat\\nInner structur e of the blocks:\\nUp Block\\n2x Bilinear\\nUpsample \\nCatDoubleConv\\nBlockDown Block  \\n2x\\nMaxPool2DDoubleConv\\nBlockDoubleConv Block\\nBN2DConv2D  \\nConv2D  ReLU\\nBN2D ReLU\\nFigure 7. Description of the U-Net architecture (Ronneberger et al., 2015), adopted as the estimator in all the experiments on natural\\nimages. We use Z= (Z1, Z2, Z3, Z4), where for the deterministic estimators Zi= 0, and for the stochastic ones Ziare statistically\\nindependent random vectors, each following a normal distribution with zero mean and identity covariance matrix. Each Ziis reshaped\\nto match the spatial size of the input to Down Block i. Cat corresponds to concatenation on the channels dimension. BN2D is a two\\ndimensional batch normalization layer (Ioffe & Szegedy, 2015). We use a ReLU activation after each BN2D layer in each DoubleConv\\nblock. There is no activation in the last Conv2D layer of the network. The only hyperparameter of the network is s. For the experiments\\non CelebA we use s= 24 (for both the inpainting and super resolution tasks), and for the experiments on ImageNet we use s= 32 .\\n17\\n\\nPage 17\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nTable 4. Full description of the critic’s architecture used in all the experiments on natural images. We use pre-activation ResNet blocks\\nand Leaky ReLU activations with a slope of 0.2everywhere (except for the last layer, where there is no activation). The output of each\\nResNet block is multiplied by 0.1. The only hyperparameter of the network is f, and the spatial extent of the input image is always\\n64×64in our experiments. f= 16 in all the CelebA experiments, and f= 32 in all ImageNet experiments. This architecture follows a\\nsimilar structure to the one described in (Mescheder et al., 2018).\\nLayer Output size Filter\\nConv2D f×64×64 3→f\\nResNet Block f×64×64 f→f→f\\nResNet Block 2f×64×64 f→f→2f\\nAverage Pooling 2D 2f×32×32 -\\nResNet Block 2f×32×32 2f→2f→2f\\nResNet Block 4f×32×32 2f→2f→4f\\nAverage Pooling 2D 4f×16×16 -\\nResNet Block 4f×16×16 4f→4f→4f\\nResNet Block 8f×16×16 4f→4f→8f\\nAverage Pooling 2D 8f×8×8 -\\nResNet Block 8f×8×8 8f→8f→8f\\nResNet Block 16f×8×8 8f→8f→16f\\nAverage Pooling 2D 16f×4×4 -\\nResNet Block 16f×4×416f→16f→16f\\nResNet Block 16f×4×416f→16f→16f\\nAverage Pooling 2D 16f×2×2 -\\nResNet Block 16f×2×216f→16f→16f\\nResNet Block 16f×2×216f→16f→16f\\nFully Connected 1 16f·2·2→1\\nthe adversarial attack of each input, as described in Appendix E.2.3. The robustness loss (Equation (7)) is included in the\\nestimator’s objective once in every three optimization steps, i.e., we always perform two estimator training steps solely with\\na GAN loss, and the robustness loss is added at the third step when training a robust model. For the optimization of the\\nestimator’ and critic’s parameters, we always use the Adam optimizer with (β1, β2) = (0 .5,0.99)and a learning rate of\\n10−4. For both models we also perform a multi-step learning rate scheduling with a decay of γ= 0.6, scheduled at the steps\\n400k,500k,600k,700kand750k. The R1gradient penalty coefficient of the critic is set to 1.\\nE.2.3. C OMPUTATION OF THE ROBUSTNESS LOSS (EQUATION (7))\\nNote that measuring the robustness of an estimator with Equation (7) involves a maximization procedure for each y\\n(Equation (6)). We approximate this maximization with 5 optimization steps using the Adam optimizer (Kingma & Ba,\\n2014) with a learning rate of 1and(β1, β2) = (0 .9,0.999) . The optimizer’s parameters are re-initialized at the beginning\\nof each training step (so its inner parameters are not transferred from step to step). The same procedure with the same\\nhyper-parameters is done both for training and validation.\\nAnother thing to note is that computing Equation (6) for each yrequires averaging over samples of Z. For the stochastic\\nestimators we sample 10 instances of Zto compute this average, and for the deterministic estimators averaging is not\\nrequired since Z= 0.\\nLastly, in the inpainting task we use ϵ= 2.5, and in the super resolution task we use ϵ= 0.553,0.276,0.138for the scaling\\nfactors ×4,×8,×16, respectively. These values of ϵensure the same bound on the adversarial input PSNR across all scaling\\nfactors. To ensure that the attack δholds∥δ∥2≤ϵ, we project δon the ϵball after each update step of the attack.\\n18\\n\\nPage 18\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nE.2.4. D ATA SETS\\nCelebA: We pre-process each source image by first resizing it to 102x102 via bilinear-interpolation and then cropping the\\ncenter 64x64 pixels, so the source images we use are of size 64x64. We use 80% of the original CelebA training data to train\\nall the algorithms (the images in the resulting subset are being chosen at random), and the remaining 20% is added to the\\noriginal CelebA validation data. We do so to have enough images for perceptual quality evaluation using metrics such as\\nFID (Heusel et al., 2017).\\nImageNet: We use the 64×64version of the ImageNet data set (Chrabaszcz et al., 2017) with no pre-processing, and with\\nthe original training and validation sets splits.\\nE.2.5. C OMPUTATION OF PERCEPTUAL QUALITY METRICS\\nWe compute FID (Heusel et al., 2017), precision and recall (Kynk ¨a¨anniemi et al., 2019) (with k= 3) using the PyTorch\\npackage (Kastryulin et al., 2019), and with the default feature extraction network of that package (InceptionV3 (Szegedy\\net al., 2015)). We randomly choose 50,000 real and fake samples to perform the evaluation (the real samples are the high\\nquality training images, and the fake samples are the outputs of the algorithm on the validation inputs). For the stochastic\\nalgorithms each fake sample corresponds to a different input, i.e., we sample 50,000 random seeds and each seed is combined\\nwith a different input to provide one output, effectively sampling one instance from pˆX|Y(·|y)for each y.\\nF. What is the rationale of utilizing GANs to compare stochastic and deterministic restoration\\nmodels?\\nAmong image restoration methods, GAN-based (Wang et al., 2018; Ledig et al., 2017; Bahat & Michaeli, 2020; Ohayon\\net al., 2021), flow-based (Lugmayr et al., 2020; Jo et al., 2021), diffusion-based (Song & Ermon, 2019; Kadkhodaie &\\nSimoncelli, 2021; Kawar et al., 2021a;b; 2022), and V AE-based (Gatopoulos et al., 2020; Liu et al., 2021a;b) techniques are\\ncurrently the most widely adopted and effective in terms of achieving high levels of perceptual quality. However, in order to\\nprovide sufficient evidence for our hypothesis in this paper, which posits that stochastic models can achieve high levels of\\nperceptual quality with higher levels of robustness compared to deterministic models, it is essential to conduct a fair and\\nunbiased comparison. For example, a stochastic flow-based method that achieves high levels of perceptual quality may\\nexhibit greater robustness compared to a deterministic GAN-based technique with similar levels of perceptual quality (as\\ndemonstrated in Appendix G). However, this does not necessarily imply that the superior performance of the flow-based\\nmethod is solely attributed to its stochasticity. Rather, it shows that a restoration algorithm with high levels of perceptual\\nquality can also exhibit robustness, which refutes the hypothesis proposed in (Choi et al., 2019). Hence, to conduct a fair\\nevaluation, it is crucial to isolate the impact of stochasticity on the model’s performance. This can be achieved by using\\nGANs, as they naturally allow to perform a comparison “on the same grounds” (same data sets, same loss, same architecture,\\nsame AI-PSNR, same hyper-parameters, etc.) by manipulating the input random seed from a degenerate distribution (to\\nobtain a deterministic model) to a non-degenerate distribution (to obtain a stochastic model). Such an effective way to isolate\\nthe impact of output stochasticiy on the model’s performance is currently much less trivial with flow-based, diffusion-based,\\nand V AE-based methods. We therefore leave the analysis of these methods for future work.\\nG. Robustness of SRFlow: results\\nWe assess the robustness of SRFlow (Lugmayr et al., 2020) by adapting the I-FGSM (Choi et al., 2019; Kurakin et al., 2017)\\nmethod to be applicable to any differentiable estimation procedure that utilizes a random seed as input. This adaptation\\nenables a fair comparison of stochastic methods with the I-FGSM attacks performed on other methods (Choi et al., 2019).\\nTo find the input attack ˜yon the SRFlow model (denoted by SRF(Y, Z)), we compute the loss E[∥SRF(y, Z)−SRF(˜y, Z)∥2]\\nfor each Y=y, averaging over 10 realizations of Z(the random seed of SRFlow), and then continue to perform 50 I-FGSM\\nupdate steps in the same fashion as described in (Choi et al., 2019), Sec. 3.1. To ensure a fair comparison with other models,\\nwe adhere to the official public implementation of the I-FGSM procedure described in (Choi et al., 2019), and use the\\nsame initialization for the attack. Additionally, we utilize the official code and pre-trained model checkpoints of SRFlow as\\nprovided by the authors. Lastly, as in (Choi et al., 2019), we perform the evaluation on the Set5 (Bevilacqua et al., 2012),\\nSet14 (Zeyde et al., 2010), and BSD100 (Martin et al., 2001) data sets.\\nThe robustness evaluation of SRFlow is presented in Figure 8. For ease of comparison, we also include the robustness\\n19\\n\\nPage 19\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\nlevels of ESRGAN (Wang et al., 2018) and EDSR (Chen et al., 2018) as reported in (Choi et al., 2019) (refer to (Choi\\net al., 2019) for the analysis of additional distortion-based models). Our results show that the robustness levels of SRFlow\\nare significantly higher than those of ESRGAN across all values of α, the hyper-parameter controlling the severity of the\\nI-FGSM attack. This confirms that even an “off the shelf” stochastic restoration algorithm with high perceptual quality can\\nexhibit much higher robustness than a deterministic algorithm with comparable output perceptual quality. Furthermore,\\nthe results show that SRFlow exhibits comparable level of robustness to EDSR and most of the distortion-based models\\nevaluated in (Choi et al., 2019). I.e., despite achieving high perceptual quality, SRFlow maintains a robustness level that is\\ncomparable to models that attain much lower levels of perceptual quality. All and all, this experiment further supports our\\nclaim that the link between high perceptual quality and low robustness (Choi et al., 2019) is valid only for deterministic\\nmappings.\\n20\\n\\nPage 20\\nReasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality\\n1\\n2\\n4\\n8\\n16\\n32\\nα(/255)0102030405060PSNRESRGAN\\nEDSR\\nSRFlow\\n(a) Set5 adversarial output PSNR.\\n1\\n2\\n4\\n8\\n16\\n32\\nα(/255)0102030405060PSNRESRGAN\\nEDSR\\nSRFlow\\n(b) Set5 adversarial input PSNR.1\\n2\\n4\\n8\\n16\\n32\\nα(/255)0102030405060PSNRESRGAN\\nEDSR\\nSRFlow\\n(c) Set14 adversarial output PSNR.\\n1\\n2\\n4\\n8\\n16\\n32\\nα(/255)0102030405060PSNRESRGAN\\nEDSR\\nSRFlow\\n(d) Set14 adversarial input PSNR.1\\n2\\n4\\n8\\n16\\n32\\nα(/255)0102030405060PSNRESRGAN\\nEDSR\\nSRFlow\\n(e) BSD100 adversarial output PSNR.\\n1\\n2\\n4\\n8\\n16\\n32\\nα(/255)0102030405060PSNRESRGAN\\nEDSR\\nSRFlow\\n(f) BSD100 adversarial input PSNR.\\nFigure 8. Comparison of adversarial output PSNR (robustness) and adversarial input PSNR (AI-PSNR) on Set5 (Bevilacqua et al., 2012),\\nSet14 (Zeyde et al., 2010), and BSD100 (Martin et al., 2001), using the I-FGSM attack (Choi et al., 2019; Kurakin et al., 2017) with\\nseveral values of α. The evaluated methods are SRFlow (Lugmayr et al., 2020), EDSR (Chen et al., 2018), and ESRGAN (Wang et al.,\\n2018). The results of EDSR and ESRGAN are copied from (Choi et al., 2019), whereas SRFlow is evaluated as described in Appendix G.21\\n\\n\\n\\n// questions\\nQ1: What problem is this paper trying to solve?\\nQ2: What are the relevant studies?\\nQ3: How does the paper solve this problem?\\nQ4: What experiments were done in the paper?\\nQ5: What gaps can be explored further?\\nQ6: Summarize the main content of the paper\\n\\n\\n// some good answer samples for other papers\\n\\n#9 Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models\\nAuthors: Matthew Dahl ; Varun Magesh ; Mirac Suzgun ; Daniel E. Ho\\n\\nAbstract: Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations. Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources.\\n\\nQ: 这篇论文试图解决什么问题？\\n\\nA: 这篇论文试图解决的问题是大型语言模型（LLMs）在法律应用中出现的“法律幻觉”（legal hallucinations）现象。这些模型在处理法律问题时可能会生成与法律事实不一致的响应，这种现象在法律领域尤其危险，因为法律工作要求严格遵守法律文本。论文通过以下四个关键贡献来探讨这个问题：\\n\\n开发了一个法律幻觉的分类体系，为未来在这个领域的研究提供了概念框架。\\n\\n发现法律幻觉在LLMs中非常普遍，当这些模型被要求回答关于随机联邦法院案件的具体、可验证问题时，幻觉发生的比例在ChatGPT 3.5中为69%，在Llama 2中为88%。\\n说明LLMs经常无法在基于反事实的法律问题设置中纠正用户的错误法律假设。\\n\\n提供证据表明LLMs不能总是预测，或者并不总是知道，它们何时在产生法律幻觉。\\n\\n这些发现警示了不应迅速且无监督地将流行的LLMs集成到法律任务中，即使是经验丰富的律师也必须对法律幻觉保持警惕，而对于那些最有可能从LLMs中受益的人——自诉当事人或无法获得传统法律资源的人来说，风险最高。\\nQ: 有哪些相关研究？\\n\\nA: 这篇论文提到了以下几项相关研究：\\n\\nChoi et al., 2022：这项研究展示了LLMs在法学院一年级考试中的表现，表明LLMs在法律相关任务上的能力。\\n\\nOpenAI, 2023b：OpenAI的研究展示了LLMs在统一律师考试（Uniform Bar Exam）中的表现。\\n\\nBlair-Stanek et al., 2023：这项研究探讨了LLMs在法律推理（statutory reasoning）方面的能力。\\n\\nGuha et al., 2023：这项工作研究了LLMs在IRAC（Issue-Rule-Application-Conclusion）分析中的表现。\\n\\nBommasani et al., 2022 和 Perlman, 2023：这些研究讨论了AI工具和系统是否可能很快取代人类律师。\\n\\nWeiser, 2023 和 SCOTUSBlog, 2023：这些报道提到了LLMs在法律领域中生成虚构案例引用和错误信息的问题。\\n\\nJi et al., 2023; Mündler et al., 2023; Manakul et al., 2023; Dhuliawala et al., 2023：这些研究探讨了LLMs在神经机器翻译、摘要生成、一般知识问答和对话生成中的幻觉问题。\\n\\nAgrawal et al., 2023：这项工作提出了一种在开放领域中研究幻觉的方法，这在法律领域中特别相关，因为法律事实和文本的准确性至关重要。\\n\\nKalai and Vempala, 2023：这项研究提出了LLMs在某些任务中必须产生幻觉的观点，因为它们必须为每个响应标记分配正概率。\\n\\nCao et al., 2018：这项研究讨论了LLMs在摘要生成中的幻觉问题。\\n\\nMaynez et al., 2020：这项研究探讨了LLMs在训练或提示下对事实的忠诚度。\\n\\nKleinberg and Raghavan, 2021：这项研究提出了“算法单一文化”（algorithmic monoculture）的概念，这在法律领域中可能导致LLMs对法律的过度简化理解。\\n\\n这些研究为理解LLMs在法律领域中的性能和局限性提供了背景，并为本文的研究提供了理论基础和实证支持。\\nQ: 论文如何解决这个问题？\\n\\nA: 论文通过以下步骤来解决大型语言模型（LLMs）在法律领域中产生幻觉的问题：\\n\\n问题定义：首先，论文明确了法律幻觉的概念，即LLMs生成的与法律事实不一致的响应。这种不一致性在法律领域尤其危险，因为法律工作要求严格遵守法律文本。\\n\\n研究设计：论文设计了一个研究框架，通过一系列法律查询任务来评估LLMs的性能。这些任务分为低复杂度、中等复杂度和高复杂度三个类别，涵盖了从简单的案件存在性验证到复杂的法律推理。\\n\\n数据构建：研究者从美国联邦法院的案例法中随机抽取了5,000个案例，涵盖了最高法院（SCOTUS）、上诉法院（USCOA）和地区法院（USDC）的案例。这些案例与法律数据库中的结构化元数据相结合，用于构建参考基础查询。\\n\\n参考基础查询：对于有明确答案的查询，研究者直接从LLMs中获取响应，并与已知的地面真实答案进行比较，以估计幻觉率。\\n\\n参考自由查询：对于没有明确答案的查询，研究者采用参考自由查询方法，通过在不同的温度下重复查询LLMs并检查其响应的一致性来估计幻觉率。\\n\\n实验执行：使用OpenAI的ChatGPT 3.5、Google的PaLM 2和Meta的Llama 2三个流行的LLMs进行实验。\\n\\n结果分析：研究者分析了LLMs在不同任务上的幻觉率，并探讨了幻觉率如何随任务复杂度、法院层级、司法管辖区、案例显著性、案例年份和LLM模型本身而变化。\\n\\n讨论限制：论文讨论了LLMs在法律研究任务中存在的其他潜在问题，包括对反事实偏见的易感性和对响应确定性的过度自信。\\n\\n提出建议：基于研究结果，论文提出了对LLMs在法律领域应用的建议，强调了在将LLMs集成到法律任务中时需要谨慎，并建议法律专业人士在使用LLMs时保持警惕。\\n\\n通过这些步骤，论文不仅揭示了LLMs在法律领域中产生幻觉的普遍性和严重性，还为如何改进LLMs以更好地适应法律实践提供了见解。\\n通过这些步骤，论文不仅揭示了LLMs在法律领域中产生幻觉的普遍性和严重性，还为如何改进LLMs以更好地适应法律实践提供了见解。\\nQ: 论文做了哪些实验？\\n\\nA: 论文进行了以下实验来研究大型语言模型（LLMs）在法律领域中的幻觉现象：\\n\\n数据构建：研究者从美国联邦法院的案例法中随机抽取了5,000个案例，涵盖了最高法院（SCOTUS）、上诉法院（USCOA）和地区法院（USDC）的案例。这些案例与法律数据库中的结构化元数据相结合，用于构建参考基础查询。\\n\\n实验设计：研究者设计了十四个任务，分为低复杂度、中等复杂度和高复杂度三个类别，以测试LLMs在不同法律查询任务上的表现。这些任务包括验证案件存在性、提供案件引用、确定案件的法院、提供案件的主要意见作者、确定案件的判决结果、提供案件的引用、确定案件是否被推翻、确定案件的教义一致性、提供案件的事实背景、确定案件的程序立场、提供案件的后续历史、确定案件的核心法律问题和中心判决等。\\n\\n参考基础查询：对于有明确答案的查询，研究者直接从LLMs中获取响应，并与已知的地面真实答案进行比较，以估计幻觉率。\\n\\n参考自由查询：对于没有明确答案的查询，研究者采用参考自由查询方法，通过在不同的温度下重复查询LLMs并检查其响应的一致性来估计幻觉率。这种方法利用了LLMs在较高温度下生成响应时的随机性，通过比较不同温度下的响应来检测幻觉。\\n\\n实验执行：研究者使用OpenAI的ChatGPT 3.5、Google的PaLM 2和Meta的Llama 2三个流行的LLMs进行实验。每个查询都在零次和三次提示设置下运行。\\n\\n结果分析：研究者分析了LLMs在不同任务上的幻觉率，并探讨了幻觉率如何随任务复杂度、法院层级、司法管辖区、案例显著性、案例年份和LLM模型本身而变化。\\n\\n讨论限制：论文讨论了LLMs在法律研究任务中存在的其他潜在问题，包括对反事实偏见的易感性和对响应确定性的过度自信。\\n\\n这些实验旨在全面评估LLMs在法律领域中的表现，特别是在生成与法律事实一致的响应方面的能力。\\n\\nQ: 有什么可以进一步探索的点？\\n\\nA: 这篇论文提出了一些可以进一步探索的点，包括：\\n\\n幻觉的分类和理解：尽管论文提出了一个法律幻觉的分类体系，但这个分类可能需要进一步细化和扩展，以更好地理解不同类型的幻觉及其在法律实践中的影响。\\n\\n幻觉的上下文依赖性：研究可以更深入地探讨幻觉如何依赖于特定的法律上下文，例如，幻觉是否在某些法律领域更为普遍，或者是否在处理特定类型的法律问题时更容易出现。\\n\\n幻觉的预防和纠正：研究可以探索如何通过改进模型训练、引入外部知识库或使用人类反馈来减少幻觉的发生，并研究如何设计系统来纠正用户的错误假设。\\n\\n模型的自我意识：研究可以进一步探索LLMs对自己生成幻觉的自我意识，以及如何提高模型对自己不确定性的表达能力。\\n\\n用户交互和信任：研究可以考察用户如何与LLMs交互，以及用户如何建立对LLMs响应的信任。这包括研究用户如何识别和处理幻觉，以及如何设计用户界面来帮助用户更好地理解模型的局限性。\\n\\n法律实践的影响：研究可以评估LLMs在法律实践中的广泛应用对法律专业人士和公众的影响，包括对法律服务的可及性和质量的影响。\\n\\n伦理和社会影响：研究可以探讨LLMs在法律领域的应用可能带来的伦理和社会问题，例如，如何确保公平性和防止不平等的加剧。\\n\\n跨司法管辖区的比较：研究可以扩展到不同司法管辖区，比较不同法律体系中LLMs的表现，以及幻觉现象在不同法律文化中的表现形式。\\n\\n法律教育和培训：研究可以探讨如何利用LLMs来改进法律教育和培训，以及如何教育未来的法律专业人士理解和应对LLMs的局限性。\\n\\n法律政策和监管：研究可以考察如何制定法律政策和监管框架来指导LLMs在法律领域的合理使用，以及如何确保这些技术的发展符合法律伦理和职业标准。\\n\\n这些研究方向有助于更全面地理解LLMs在法律领域的潜力和挑战，并为未来的法律实践和技术发展提供指导。\\n\\nQ: 总结一下论文的主要内容\\n\\nA: 这篇论文探讨了大型语言模型（LLMs）在法律领域中的“法律幻觉”现象，即模型生成的响应与法律事实不一致的问题。论文的主要内容包括：\\n\\n研究背景：介绍了LLMs在法律领域的潜在变革作用，以及由于幻觉问题而面临的挑战。\\n\\n法律幻觉的类型：提出了一个法律幻觉的分类体系，区分了封闭领域和开放领域的幻觉，以及与输入提示和训练语料库的一致性问题。\\n\\n研究方法：设计了一套法律查询任务，分为低、中、高复杂度，以评估LLMs在不同任务上的表现。\\n\\n实验设计：通过随机抽取的联邦法院案例，构建了参考基础查询和参考自由查询，以估计幻觉率。\\n\\n实验结果：发现LLMs在回答关于随机联邦法院案件的具体、可验证问题时，幻觉发生的比例非常高，尤其是在处理复杂任务时。\\n\\n额外挑战：探讨了LLMs在处理基于错误法律前提的查询时的易感性，以及它们对自己生成幻觉的不确定性。\\n\\n讨论限制：论文讨论了LLMs在法律领域应用的局限性，包括对法律专业人士和自诉当事人的风险。\\n\\n结论：论文得出结论，尽管LLMs在法律研究任务上显示出潜力，但当前的局限性，特别是生成准确和可靠法律陈述的能力，严重阻碍了这一目标。\\n\\n论文强调了在将LLMs集成到法律任务中时需要谨慎，并建议法律专业人士在使用LLMs时保持警惕，特别是对于那些最有可能从LLMs中受益的人。\\n\\n#1 Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models\\nAuthors: Zixiang Chen ; Yihe Deng ; Huizhuo Yuan ; Kaixuan Ji ; Quanquan Gu\\n\\nHarnessing the power\\nHarnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.\\n\\nQ: 这篇论文试图解决什么问题？\\n\\nA: 这篇论文试图解决的问题是：如何将一个弱的大型语言模型（LLM）通过自我博弈（self-play）机制增强为一个强大的LLM，而无需额外的人类标注数据。具体来说，论文提出了一种新的微调方法，称为Self-Play Fine-Tuning (SPIN)，它从监督微调模型开始，通过LLM与自身实例的对抗过程来提升模型能力。这种方法的核心在于，LLM通过生成自己的训练数据并从这些数据中学习，从而逐步提升性能，最终达到与人类标注数据分布一致的状态。\\n\\nQ: 有哪些相关研究？\\n\\nA: 这篇论文提到了以下几类相关研究：\\n\\n自我博弈（Self-Play）：自我博弈是一种学习策略，其中算法通过与自己的副本进行交互来学习。这种方法在多智能体强化学习（MARL）中得到了显著的关注，例如AlphaGo Zero和AlphaZero就是通过自我博弈机制实现的。论文中的SPIN方法借鉴了自我博弈的思想，将这一策略应用于大型语言模型的增强。\\n\\n合成数据用于LLMs：在监督微调（SFT）的背景下，人工制作的数据已被证明是提高LLM性能的有效来源。然而，获取足够数量的高质量数据在成本上是一个挑战。因此，使用合成数据作为人类数据的代理变得越来越流行。这种方法通常利用先进的LLM（如GPT系列）作为指导来生成高质量的数据。与之前使用更先进的模型生成合成数据的研究不同，SPIN方法直接从目标模型本身生成合成数据。\\n\\n课程学习（Curriculum Learning）：在深度学习中，使用按战略意义排列的数据样本进行模型训练，可以比随机打乱的数据带来更好的性能。这种方法被称为课程学习。SPIN方法与课程学习有相似之处，其中训练数据是迭代发展的——从容易与人类标注数据区分的响应开始，逐渐过渡到更具挑战性的实例。\\n\\n这些相关研究为SPIN方法提供了理论基础和实践背景，SPIN结合了自我博弈、合成数据生成和课程学习的思想，提出了一种新的LLM增强方法。\\n\\nQ: 论文如何解决这个问题？\\n\\nA: 论文提出了一种名为Self-Play Fine-Tuning (SPIN)的新方法来解决将弱大型语言模型（LLM）转换为强模型的问题，而无需额外的人类标注数据。SPIN的核心思想是自我博弈机制，具体步骤如下：\\n\\n自我博弈机制：SPIN从监督微调（SFT）模型开始，让LLM通过与自身实例的对抗来提升能力。在这个过程中，LLM既是主要玩家（试图区分人类数据和LLM生成的数据），也是对手玩家（生成尽可能接近人类数据的响应）。\\n\\n生成合成数据：使用当前迭代的LLM（对手玩家）为SFT数据集中的提示生成响应。这些响应作为合成数据，用于训练主要玩家。\\n\\n训练主要玩家：主要玩家的目标是最大化从目标数据分布到对手玩家分布的期望值差距。通过优化一个特定的目标函数，主要玩家学会区分人类标注的响应和LLM生成的响应。\\n\\n更新对手玩家：对手玩家的目标是生成与主要玩家难以区分的响应。这通过最大化一个结合了主要玩家评估和KL正则化的目标函数来实现，以防止模型偏离太远。\\n\\n迭代过程：在每个迭代中，使用上一个迭代的LLM作为对手玩家生成合成数据，然后训练主要玩家以区分这些响应。接着，根据主要玩家的评估更新对手玩家。这个过程不断迭代，直到LLM的性能达到最优。\\n\\n理论证明：论文提供了理论分析，证明了当LLM的策略与目标数据分布一致时，SPIN方法的全局最优解才能实现。\\n\\n通过这种方法，SPIN能够有效地利用人类标注的数据，通过自我博弈的过程，逐步提升LLM的性能，最终达到与人类标注数据分布一致的状态。\\n\\nQ: 论文做了哪些实验？\\n\\nA: 论文在多个基准数据集上评估了SPIN方法，包括：\\n\\nHuggingFace Open LLM Leaderboard：这是一个广泛使用的评估基准，涵盖了6个不同的数据集，分别针对LLM的常识推理、多任务语言理解、人类虚假陈述模仿和数学问题解决等特定能力。作者使用这个基准来评估SPIN在不同迭代下的性能提升。\\n\\nMT-Bench：这是一个多任务语言理解基准，用于评估模型在各种语言理解任务上的性能。\\n\\nBig-Bench：这是一个包含多个子任务的基准，用于评估模型在因果推理、体育理解、形式谬误和数学问题解决等任务上的性能。\\n\\nOpenBookQA：这是一个开放书籍问答任务，用于评估模型在问答任务上的性能。\\n\\n在实验中，作者展示了SPIN方法在多个数据集上显著提升了LLM的性能，甚至在某些情况下超过了通过直接偏好优化（DPO）训练的模型，尽管后者使用了额外的人类偏好数据。此外，作者还进行了消融研究，探讨了合成数据集大小和训练周期对SPIN性能的影响。实验结果表明，迭代训练是SPIN方法的关键组成部分，因为它打破了多周期训练的性能限制。\\n\\nQ: 有什么可以进一步探索的点？\\n\\nA: 尽管SPIN方法在多个基准测试中显示出了显著的性能提升，但仍有一些潜在的研究方向和改进点：\\n\\n动态目标数据分布：论文中的SPIN方法专注于一个固定的由人类生成的目标数据分布，这在一定程度上限制了LLM性能的提升。未来的研究可以探索如何使目标数据分布动态变化，以进一步提升LLM的性能，甚至达到超人水平。\\n\\n减少合成数据量：生成合成数据需要大量计算资源。研究如何减少所需的合成数据量，同时保持或提高SPIN方法的性能，是一个有前景的研究方向。\\n\\n自我博弈的稳定性和收敛性：虽然理论上证明了SPIN方法在满足一定条件下会收敛，但在实践中，如何确保自我博弈过程的稳定性和快速收敛仍然是一个挑战。未来的研究可以探索更有效的策略来控制自我博弈过程。\\n\\n应用到其他领域：SPIN方法目前主要在自然语言处理领域进行了探索。将其应用到其他领域，如计算机视觉、语音识别等，可能会带来新的洞见和挑战。\\n\\n自我博弈的泛化能力：研究SPIN方法在不同任务和领域中的泛化能力，以及如何通过自我博弈来提升模型的泛化性能，是一个值得探索的方向。\\n\\n自我博弈的可解释性：提高自我博弈过程中模型决策的可解释性，可以帮助我们更好地理解模型的内部工作机制，从而为模型的改进提供指导。\\n\\n自我博弈与人类交互：研究如何将自我博弈与人类交互相结合，以进一步提升模型的性能和适应性，是一个有潜力的研究方向。\\n\\nQ: 总结一下论文的主要内容\\n\\nA: 本论文提出了一种名为Self-Play Fine-Tuning (SPIN)的新方法，旨在将弱大型语言模型（LLM）通过自我博弈机制转换为强模型，而无需额外的人类标注数据。SPIN方法的核心在于LLM通过与自身实例的对抗来提升能力，其中LLM既是主要玩家（尝试区分人类数据和LLM生成的数据），也是对手玩家（生成尽可能接近人类数据的响应）。通过迭代过程，SPIN逐步提升LLM的性能，最终使其与人类标注数据分布一致。理论上，论文证明了当LLM策略与目标数据分布一致时，SPIN方法的全局最优解才能实现。实验结果表明，SPIN在多个基准数据集上显著提升了LLM的性能，甚至超过了通过直接偏好优化（DPO）训练的模型。这表明自我博弈是一个有前景的策略，可以在不依赖专家对手的情况下实现LLM的人类水平性能。\\n\\n#1 An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction \\nAuthors: Zaratiana Urchade ; Nadi Tomeh ; Pierre Holat ; Thierry Charnois\\n\\nIn this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.\\n\\nQ: 这篇论文试图解决什么问题？\\n\\nA: 这篇论文试图解决的问题是联合实体和关系抽取（Joint Entity and Relation Extraction, JERE）在自然语言处理（NLP）中面临的挑战。具体来说，论文提出了一种新的方法，通过将JERE任务框架化为一个条件序列生成问题来解决以下问题：\\n\\n传统的管道模型（pipeline models）独立地训练和实现实体识别和关系抽取，这往往导致错误传播。\\n\\n现有的端到端模型（end-to-end models）虽然允许使用共享表示和联合优化损失函数，但它们基本上仍然是基于管道的，实体和关系预测由不同的分类头执行，从而忽略了这些任务之间的潜在交互。\\n现有的端到端模型（end-to-end models）虽然允许使用共享表示和联合优化损失函数，但它们基本上仍然是基于管道的，实体和关系预测由不同的分类头执行，从而忽略了这些任务之间的潜在交互。\\n\\n最近的进展转向了“真正的”端到端解决方案，其中实体和关系的预测是交织在一起的，通过自回归模型实现。然而，这些模型在将输出与输入文本联系起来方面存在改进空间，特别是在确保输出在语义上连贯的同时与输入文本保持上下文联系。\\n\\n为了解决这些问题，论文提出了一种自回归变换器编码器-解码器模型，该模型生成线性化图而不是生成纯文本。模型使用指向机制（pointing mechanism）在动态词汇表上操作跨度（spans）和关系类型，这允许捕捉实体和关系的结构特征和边界，同时通过指向机制将生成的输出与原始文本联系起来。\\n\\nQ: 有哪些相关研究？\\n\\nA: 相关研究可以分为几个主要类别，包括传统的信息抽取（IE）方法、端到端的联合实体和关系抽取模型，以及生成式信息抽取方法。以下是一些代表性的研究：\\n\\n传统信息抽取方法\\n管道模型：这些模型通常包括独立的实体识别和关系抽取阶段，但这种方法容易受到错误传播的影响。例如，Brin (1999) 提出了一种基于规则的方法来提取实体间的关系，而 Roth 和 Yih (2004) 提出了一种线性规划方法来进行自然语言任务的全局推理。\\n\\n端到端模型：这些模型旨在通过联合优化损失函数来提高实体识别和关系抽取的性能。例如，Wadden 等人 (2019) 使用上下文化跨度表示进行实体、关系和事件提取。\\n\\n端到端的联合实体和关系抽取模型\\n表填充方法：这些模型将联合信息提取任务视为表填充问题。例如，Tab-Seq (Wang 和 Lu 2020) 通过将实体和关系视为表格，并使用二维CNN来捕捉和建模局部依赖关系。\\n\\n统一标签空间：一些模型通过消除实体检测和关系分类的标签空间分离来实现联合提取。例如，UniRE (Wang 等人 2021) 使用统一分类器来预测单词对表中每个单元格的标签。\\n\\n生成式信息抽取方法\\n自回归模型：这些模型将联合实体-关系任务视为生成过程，使用增强语言来编码和解码结构信息。例如，TANL (Paolini 等人 2021) 将联合信息提取任务视为从纯文本到增强自然语言的翻译过程。\\n\\n结构生成：一些模型通过编码目标结构作为一系列结构构建动作，并使用条件语言模型来预测这些动作来进行实体和关系提取。例如，ASP (Liu 等人 2022) 使用条件语言模型来预测结构构建动作。\\n\\n其他相关研究\\n实体链接：Cao 等人 (2021) 提出了一种自回归实体检索方法，使用语言模型生成实体链接结果。\\n\\n事件提取：Li 等人 (2021) 提出了一种文档级事件论元提取方法，通过条件生成来实现。\\n\\n文档级关系提取：Giorgi 等人 (2022) 提出了一种序列到序列的方法来进行文档级关系提取。\\n\\n这些研究展示了信息抽取领域的多样性和不断发展，特别是在端到端模型和生成式模型方面的最新进展。\\nQ: 论文如何解决这个问题？\\n\\nA: 论文提出了一个名为ATG（Autoregressive Text-to-Graph）的框架，通过以下关键方法解决了联合实体和关系提取的问题：\\n\\n自回归变换器编码器-解码器架构：模型使用变换器（Transformer）架构，其中编码器处理输入文本序列，解码器则生成线性化图表示。这种架构允许模型捕捉输入文本的全局上下文信息。\\n\\n指向机制：在解码器中使用指向机制，这允许模型在生成输出时直接引用输入文本中的特定位置。这种机制确保了生成的实体跨度与输入文本紧密关联，提供了明确的文本基础。\\n\\n动态词汇表：模型在解码过程中使用一个动态词汇表，其中包括跨度（spans）、特殊标记（如<SEP>）和关系类型（relation types）的嵌入。这种动态词汇表使得模型能够直接生成实体跨度和关系，而不是生成独立的纯文本。\\n\\n线性化图表示：模型的目标是生成一个线性化图，其中节点代表实体跨度，边代表关系三元组。这种表示形式捕捉了实体和关系的结构特征，同时保持了与原始文本的联系。\\n\\n约束解码：在推理阶段，模型通过状态转换约束来引导生成过程，确保输出的图结构是良好形成的。这种结构化的生成过程有助于生成有效的信息抽取图。\\n\\n句子增强：为了解决模型倾向于生成短序列的问题，论文提出了句子增强技术，通过随机连接训练集中的句子来增加训练样本的多样性和长度。\\n\\n通过这些方法，ATG框架能够有效地从非结构化文本中提取实体和关系，并以一种结构化的形式表示它们。这种表示形式不仅捕捉了实体和关系的边界，而且还通过指向机制与原始文本紧密关联，从而提高了模型的准确性和可解释性。\\nQ: 论文做了哪些实验？\\n\\nA: 论文在三个基准数据集上评估了所提出的ATG模型：CoNLL 2004、SciERC和ACE 05。实验包括以下几个方面：\\n\\n模型训练：使用AdamW优化器训练模型，采用学习率预热和衰减策略。训练过程中，模型的编码器初始化为预训练的变换器编码器，而解码器是随机初始化的。\\n\\n基准模型比较：将ATG模型与现有的联合实体和关系提取方法进行比较，包括基于跨度的/表填充方法和生成式信息提取方法。\\n\\n消融研究：分析模型中不同组件的影响，例如解码器层数、位置编码和结构编码的重要性。\\n\\n序列排序：比较了两种不同的序列排序方法（排序和随机）对模型性能的影响。\\n\\n句子增强：研究了句子增强技术对模型性能的影响，特别是在不同增强大小下的性能变化。\\n\\n注意力分析：通过可视化模型的自注意力和交叉注意力模式，提供了模型决策过程的解释性。\\n\\n结构嵌入分析：分析了在训练过程中学习到的结构嵌入的相似性，以了解模型是否能够区分不同类型的结构元素（如头实体、尾实体和关系类型）。\\n\\n超参数调整：调整了模型的超参数，如学习率、预热步骤和衰减率，以及句子增强的超参数B。\\n\\n性能评估：使用实体F1分数和关系F1分数（包括边界和严格评估）来评估模型在三个数据集上的性能。\\n\\n这些实验旨在验证ATG模型的有效性，并通过与现有方法的比较来展示其竞争力。此外，消融研究和注意力分析有助于理解模型的内部工作机制。\\nQ: 有什么可以进一步探索的点？\\n\\nA: 尽管论文提出了一种有效的联合实体和关系提取方法，但仍有一些潜在的研究方向可以进一步探索：\\n\\n模型解释性：虽然论文通过注意力分析提供了模型决策过程的一些见解，但可以进一步研究模型的可解释性，例如通过更深入的模型解释技术，如LIME或SHAP。\\n\\n多语言和跨领域泛化：论文主要在英文数据集上进行了实验。研究模型在多语言和跨领域数据上的泛化能力，以及如何适应不同的语言和领域，是一个有趣的方向。\\n\\n实体和关系的多样性：论文中的数据集主要关注有限的实体和关系类型。研究模型如何处理更多样化的实体和关系类型，特别是在复杂或领域特定的文本中，可能是一个挑战。\\n\\n上下文敏感性：虽然自回归模型在一定程度上考虑了上下文，但可以探索更复杂的上下文建模技术，如上下文变换器或记忆增强模型，以提高模型对长距离依赖的捕捉能力。\\n\\n生成质量：论文主要关注模型在实体和关系抽取任务上的性能，但可以进一步研究生成的图结构的质量，例如通过人工评估或图结构分析。\\n\\n知识图谱集成：论文将实体和关系提取视为构建知识图谱的基础任务。研究如何将提取的实体和关系有效地集成到知识图谱中，以及如何利用知识图谱来指导提取过程，是一个有前景的方向。\\n\\n实时和增量学习：现有的模型训练和评估通常是离线的。研究如何使模型能够进行实时学习和增量更新，以适应动态变化的数据和环境，具有实际应用价值。\\n\\n模型压缩和优化：为了在资源受限的设备上部署模型，研究模型压缩和优化技术，如知识蒸馏、模型剪枝和量化，是必要的。\\n\\n这些方向不仅有助于提高现有模型的性能，还可以推动信息抽取和自然语言处理领域的整体进步。\\n\\nQ: 总结一下论文的主要内容\\n\\nA: 这篇论文提出了一种名为ATG（Autoregressive Text-to-Graph）的新型方法，用于从非结构化文本中联合提取实体和关系。以下是论文的主要内容总结：\\n\\n目标：解决传统信息抽取方法中的错误传播问题，并提高现有端到端模型在实体和关系预测中的交互性。\\n\\n方法：\\n\\n自回归变换器编码器-解码器架构：使用变换器架构处理输入文本序列，并生成线性化图表示，其中节点代表实体跨度，边代表关系三元组。\\n\\n指向机制：在解码器中使用指向机制，确保生成的实体跨度直接与输入文本关联。\\n\\n动态词汇表：包含跨度、特殊标记和关系类型嵌入的动态词汇表，允许直接从文本生成结构。\\n\\n约束解码：在推理阶段使用状态转换约束，确保输出图结构的完整性。\\n\\n实验：\\n\\n在CoNLL 2004、SciERC和ACE 05三个基准数据集上进行评估。\\n与现有的联合实体和关系提取方法进行比较，包括基于跨度的/表填充方法和生成式信息提取方法。\\n\\n进行了消融研究，分析了模型组件的影响，如解码器层数、位置编码和结构编码。\\n\\n结果：\\n\\nATG模型在所有数据集上展现出竞争力，特别是在SciERC和CoNLL 2004数据集上取得了最先进的结果。\\n\\n模型通过自注意力和交叉注意力可视化展示了对输入文本的理解和利用。\\n\\n注意力分析揭示了模型在生成实体和关系时的决策过程。\\n结论：\\n\\nATG框架通过直接生成线性化图表示，成功捕捉了实体和关系的结构特征、边界和交互性。\\n\\n指向机制提供了与原始文本的强有力联系，而动态词汇表则允许模型以更紧凑的形式表示信息。\\n未来工作：\\n\\n提高模型的解释性，特别是在理解模型如何区分不同类型的结构元素方面。\\n\\n探索多语言和跨领域泛化，以及在更复杂或领域特定文本中的应用。\\n研究实时和增量学习，以便在资源受限的环境中部署模型。\\n\\n#2 LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning\\nAuthors: Hongye Jin ; Xiaotian Han ; Jingfeng Yang ; Zhimeng Jiang ; Zirui Liu ; Chia-Yuan Chang ; Huiyuan Chen ; Xia Hu\\n\\nThis work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length.\\n\\nQ: 这篇论文试图解决什么问题？\\n\\nA: 这篇论文试图解决大型语言模型（LLMs）在处理长输入序列时的局限性问题。具体来说，论文关注以下几个核心问题：\\n\\nLLMs在预训练阶段的序列长度限制：由于LLMs在训练时使用固定长度的序列，这限制了它们在推理阶段处理超出预训练上下文窗口长度的长输入序列的能力。\\n\\n长上下文处理能力：论文认为现有的LLMs本身具有处理长上下文的固有能力，但由于预训练时的相对位置编码（如RoPE）在推理时遇到未见过的相对位置（out-of-distribution, O.O.D.），导致性能下降。\\n\\n无需微调的上下文窗口扩展方法：论文提出一种名为Self-Extend的方法，旨在通过简单的修改来扩展LLMs的上下文窗口，而无需任何微调。这通过在推理阶段应用FLOOR操作来映射未见过的相对位置到训练阶段已知的位置来实现。\\n\\n性能评估：论文通过语言建模、合成长上下文任务和真实世界长上下文任务来评估Self-Extend方法的有效性，并与现有的微调方法进行比较。\\n\\n短上下文任务的性能保持：论文还探讨了Self-Extend方法在短上下文任务上的性能，以确保扩展上下文窗口的同时不会损害模型在标准任务上的表现。\\n\\n总结来说，这篇论文旨在通过提出一种无需微调的方法来扩展LLMs的上下文窗口，以充分利用它们的固有能力来处理长输入序列，并在各种任务上进行性能评估。\\n\\nQ: 有哪些相关研究？\\n\\nA: 这篇论文中提到了多个相关研究，它们主要集中在如何扩展大型语言模型（LLMs）的上下文窗口，以及如何提高LLMs处理长序列的能力。以下是一些关键的相关研究：\\n\\nXiong et al. (2023): 提出了一种通过微调模型来扩展上下文窗口的方法，这种方法需要在大量扩展文本上进行微调。\\n\\nChen et al. (2023a, 2023b): 提出了'CLEX'和'PI'两种方法，它们旨在通过不同的方式扩展上下文窗口，但通常需要一些微调步骤。\\n\\nPeng et al. (2023b): 提出了'Yarn'方法，这是一种基于微调的上下文窗口扩展技术。\\n\\nXiao et al. (2023): 提出了一种避免微调的方法，主要依赖于序列中的局部信息，但可能在有效扩展上下文窗口方面存在局限性。\\n\\nHan et al. (2023): 提出了'Lm-infinite'方法，这是一种简单的在线长度泛化技术，用于扩展LLMs。\\n\\nDing et al. (2023): 提出了'Longnet'方法，用于扩展Transformer模型以处理更长的序列。\\n\\nSu et al. (2023): 提出了RoPE（Rotary Position Embedding）技术，用于在Transformer模型中处理长序列。\\n\\nZaheer et al. (2020): 提出了Big Bird模型，这是一种为长序列设计的Transformer模型。\\n\\nDai et al. (2019): 提出了Transformer-XL模型，它通过注意力衰减来处理长序列。\\n\\nBrown et al. (2020): 提出了GPT-3模型，它使用了学习到的位置嵌入。\\n\\nVaswani et al. (2017): 提出了原始的Transformer模型，这是许多后续模型的基础。\\n\\n这些研究为LLMs在处理长序列方面的挑战提供了不同的解决方案，包括微调、位置编码的改进、注意力机制的设计等。论文提出的Self-Extend方法试图在不进行微调的情况下，通过扩展上下文窗口来提高LLMs处理长序列的能力。\\n\\nQ: 论文如何解决这个问题？\\n\\nA: 论文提出了一种名为Self-Extend的方法来解决大型语言模型（LLMs）在处理长输入序列时的局限性问题。Self-Extend的核心思想是通过构建双级注意力信息（group level和neighbor level）来扩展LLMs的上下文窗口，而无需进行任何微调。以下是Self-Extend方法的关键步骤：\\n\\n双级注意力机制：Self-Extend引入了两种级别的注意力机制。第一级是组级别（group level），用于处理长距离的token；第二级是邻居级别（neighbor level），用于处理一定范围内的相邻token。\\n\\nFLOOR操作：为了解决预训练时未见过的相对位置（O.O.D.）问题，Self-Extend在组级别上应用了FLOOR（整数除法）操作。这个操作将未见过的大的相对位置映射到预训练时已知的位置，从而允许LLMs在不进行微调的情况下维护更长文本的连贯性。\\n\\n注意力合并：在合并组级别和邻居级别的注意力时，Self-Extend通过替换邻居token窗口外的注意力值来实现。这样，模型在生成特定token时，仍然能够精确地建模邻居token。\\n\\n无需微调：Self-Extend仅在推理阶段修改注意力机制，不需要任何训练或微调。这使得它成为一个即插即用的解决方案，可以轻松地应用于现有的LLMs。\\n\\n性能评估：论文通过在语言建模、合成长上下文任务和真实世界长上下文任务上的实验来评估Self-Extend的有效性。结果表明，Self-Extend能够有效地扩展现有LLMs的上下文窗口长度，并且在某些任务上甚至超过了基于微调的方法。\\n\\n总结来说，Self-Extend通过在不进行微调的情况下扩展LLMs的上下文窗口，利用了LLMs处理长序列的固有能力。通过引入双级注意力机制和FLOOR操作，Self-Extend能够在不牺牲短序列性能的前提下，显著提高LLMs在长序列任务上的性能。\\n\\nQ: 论文做了哪些实验？\\n\\nA: 论文中进行了一系列的实验来评估提出的Self-Extend方法在不同任务上的性能。以下是主要的实验内容：\\n\\n语言建模性能：在PG19数据集上评估Self-Extend在不同序列长度下的困惑度（Perplexity, PPL）。这可以帮助理解Self-Extend在语言建模任务上的表现，尤其是在超出预训练上下文窗口长度时的性能。\\n\\n合成长上下文任务：通过Passkey检索任务来测试模型在长序列中检索信息的能力。这个任务要求模型在长文本序列中找到特定的信息（如随机放置的五位数密码），以评估其对长距离信息的敏感性。\\n\\n真实世界长上下文任务：使用两个真实世界的数据集LongBench和L-Eval来评估Self-Extend在处理长上下文任务时的性能。这些数据集包含了多种长文本理解任务，如问答、摘要和多文档问答等。\\n\\n短上下文任务：在Hugging Face Open LLM Leaderboard上评估Self-Extend在标准短上下文任务上的性能，包括ARC-Challenge、HellaSwag、MMLU、TruthfulQA和GSM8K。这有助于了解Self-Extend是否会影响模型在短序列任务上的表现。\\n\\n消融研究：研究了组大小（group size）和邻居窗口大小（neighbor window）对Self-Extend性能的影响。这有助于理解这些超参数对模型性能的具体影响。\\n\\n通过这些实验，论文展示了Self-Extend在不同类型任务上的有效性，特别是在扩展上下文窗口长度方面。实验结果表明，Self-Extend能够在不进行微调的情况下显著提高LLMs处理长序列的能力，并且在某些任务上甚至超过了基于微调的方法。此外，Self-Extend在短上下文任务上的性能几乎不受影响，表明其对模型原有性能的兼容性。\\n\\nQ: 有什么可以进一步探索的点？\\n\\nA: 论文提出了Self-Extend方法来扩展大型语言模型（LLMs）的上下文窗口，但仍有一些潜在的研究方向可以进一步探索：\\n\\n更高效的注意力机制：虽然Self-Extend通过FLOOR操作简化了长距离注意力计算，但这种方法可能在处理更长序列时效率不高。可以考虑更高效的注意力机制，如Flash Attention（Dao et al., 2022），以提高处理长序列的效率。\\n\\n更复杂的映射方法：论文中使用了简单的FLOOR操作来映射未见过的相对位置。可以尝试更复杂的映射方法，以实现更好的长上下文理解能力和更长的上下文窗口扩展。\\n\\n不同位置编码的模型：Self-Extend是基于RoPE位置编码的模型提出的。可以探索在其他类型的位置编码（如绝对位置编码）上应用Self-Extend，以验证其普适性。\\n\\n更大的模型和更长的上下文：论文中使用的模型和上下文长度可能限制了Self-Extend的潜力。在更大的模型和更长的上下文长度上测试Self-Extend，可以帮助我们更好地理解其在实际应用中的性能。\\n\\n长上下文任务的标准化评估：目前对于长上下文任务的评估标准并不统一，这可能导致评估结果的不一致。开发标准化的评估方法可以帮助更准确地衡量模型在长上下文理解上的能力。\\n\\n模型的泛化能力：虽然Self-Extend在某些任务上表现良好，但其泛化能力，特别是在未见过的长序列上的表现，仍需进一步研究。\\n\\n模型的可解释性：理解Self-Extend如何影响模型的内部表示和注意力分布，可以提供关于其工作原理的洞察，并可能指导未来的改进。\\n\\n计算资源的优化：考虑到长序列处理对计算资源的需求，探索如何优化Self-Extend以减少计算成本也是一个重要的研究方向。\\n\\n通过这些进一步的探索，可以更深入地理解Self-Extend的工作原理，优化其性能，并扩展其在长上下文理解任务中的应用。\\n\\nQ: 总结一下论文的主要内容\\n\\nA: 这篇论文提出了一种名为Self-Extend的方法，旨在扩展大型语言模型（LLMs）的上下文窗口，以便更好地处理长输入序列，而无需进行微调。以下是论文的主要内容总结：\\n\\n背景与动机：\\n\\nLLMs在处理长输入序列时面临挑战，因为它们的训练序列长度有限，这限制了它们在推理阶段处理超出预训练上下文窗口长度的序列的能力。\\n\\n论文认为现有的LLMs本身具有处理长上下文的固有能力，但受限于预训练时的相对位置编码（如RoPE）在推理时遇到未见过的相对位置（O.O.D.）问题。\\n\\n提出的方法：\\n\\nSelf-Extend通过构建双级注意力信息（组级别和邻居级别）来扩展LLMs的上下文窗口。\\n\\n组级别注意力用于处理长距离token，通过FLOOR操作将未见过的大相对位置映射到已知位置。\\n\\n邻居级别注意力用于处理一定范围内的相邻token，保持原有的注意力机制不变。\\n\\n实验评估：\\n\\n在语言建模、合成长上下文任务（如Passkey检索）和真实世界长上下文任务（如LongBench和L-Eval数据集）上进行了广泛的实验。\\n\\nSelf-Extend在不进行微调的情况下，能够有效地扩展现有LLMs的上下文窗口长度，并在某些任务上超过了基于微调的方法。\\n\\n主要贡献：\\n\\n提出了Self-Extend方法，无需微调即可扩展LLMs的上下文窗口。\\n\\n通过实验证明了Self-Extend在处理长上下文任务上的优越性能。\\n\\n强调了LLMs处理长上下文的潜在能力，并展示了通过简单的修改即可实现上下文窗口扩展的可能性。\\n\\n讨论与未来工作：\\n\\nSelf-Extend的局限性包括缺乏Flash Attention的实现和在过大的组大小下的性能下降。\\n\\n未来的工作包括实现Flash Attention以提高效率，测试Self-Extend在其他位置编码模型上的性能，以及探索更复杂的映射方法来实现更长的上下文窗口扩展。\\n\\n总的来说，论文提出了一种新颖的方法来扩展LLMs的上下文窗口，以更好地处理长序列输入，并通过实验验证了其有效性。这为LLMs在长上下文理解任务中的应用提供了新的思路。\\n\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(\n",
    "    paper_context=paper_str,\n",
    "    questions=questions,\n",
    "    few_shot_examples=few_shot_examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2ask = prompt_template.format(\n",
    "    paper_context=paper_str,\n",
    "    questions=questions,\n",
    "    few_shot_examples=few_shot_examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (0.27.2)\n",
      "Requirement already satisfied: requests>=2.20 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from requests>=2.20->openai) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /data/yixin/anaconda/aipaper/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "# gpt4 turbo\n",
    "llm = ChatOpenAI(openai_api_key=\"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\", model=\"gpt-4-1106-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_template),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke(\n",
    "    {\n",
    "        \"paper_context\": paper_str,\n",
    "        \"questions\": questions,\n",
    "        \"few_shot_examples\": few_shot_examples\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q1: 这篇论文试图解决什么问题？\\nA: 这篇论文试图解决随机恢复算法与确定性恢复算法相比的额外优势问题，进一步证明了随机方法的使用价值。论文首先证明了任何恢复算法如果能够达到完美的感知质量并且与输入一致，那么它必须是后验采样器，并且必须是随机的。其次，论文展示了确定性恢复算法可能达到高感知质量，但其实是通过采用极端敏感的映射来填补所有可能的源图像空间，使得它们对对抗性攻击非常脆弱。最后，论文展示了通过增强随机算法的鲁棒性几乎不影响其感知质量，并提高了输出的多样性。\\n\\nQ2: 有哪些相关研究？\\nA: 相关研究主要集中在图像恢复领域的现代方法，尤其是随机恢复算法和确定性恢复算法的比较。在最近几年内，随机恢复算法（如Lugmayr等人的研究，Bahat和Michaeli的工作，Ohayon等人的研究，Kawar等人的研究，Saharia等人的研究，Kadkhodaie和Simoncelli的研究，Song和Ermon的研究）开始受到关注。这些算法不是为给定的退化输入提供单一恢复图像，而是从条件分布中采样。此外，论文还参考了确定性恢复算法在感知质量方面的能力（如Wang等人，Blau和Michaeli，Ledig等人，Yu等人，Zhao等人，Yi等人，Galteri等人的工作）。\\n\\nQ3: 论文如何解决这个问题？\\nA: 论文通过以下步骤来解决这个问题：\\n1. 通过理论证明说明任何能够生成与输入一致且感知质量完美的恢复算法必须是后验采样器，因此必须是随机的。\\n2. 实证展示确定性恢复算法为了达到高感知质量而表现出的不稳定行为，并表明这种行为导致了对抗性攻击的高敏感性。\\n3. 发展了一种新的随机估计器的鲁棒性概念，并且展示了增强随机算法的鲁棒性可以改善其输出多样性而对感知质量影响不大。\\n\\nQ4: 论文做了哪些实验？\\nA: 论文进行了多项实验来验证其理论和假设：\\n1. 在CelebA数据集上对几种一致的恢复算法进行了实验，包括随机和确定性的算法，并展示了它们在图像修复任务上的输出样本。\\n2. 实证展示了确定性恢复算法为了达到高感知质量而采取的不稳定行为，以及它们对抗性攻击的敏感性。\\n3. 展示了通过增强随机算法的鲁棒性后，对输出多样性的改善以及对感知质量的影响。\\n\\nQ5: 有什么可以进一步探索的点？\\nA: 论文中提出的发现和方法可以在多个方向上进一步探索：\\n1. 在其他类型的退化和恢复任务上验证随机和确定性算法的比较结果。\\n2. 进一步研究如何优化随机算法的输出多样性，同时保持或提高感知质量。\\n3. 探索不同类型的鲁棒性增强技术在其他形式的随机恢复算法上的应用。\\n4. 研究如何将随机性和鲁棒性的概念应用到更广泛的机器学习和信号处理任务中。\\n\\nQ6: 总结一下论文的主要内容\\nA: 论文的主要内容是研究随机恢复算法相比于确定性恢复算法在鲁棒性、一致性和感知质量方面的优势。论文通过理论证明和实证实验展示了随机方法的优点，并提出了一种方法来增强随机算法的鲁棒性而不牺牲感知质量。实验结果表明，相比于确定性方法，随机方法在对抗性攻击下更为鲁棒，并且还能改善输出的多样性。论文为未来在随机恢复方法方面的研究提供了新的动机和方向。'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2FAQ = {}\n",
    "id2FAQ['2211.08944v3']= output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('id2FAQ.json', 'w') as f:\n",
    "    json.dump(id2FAQ, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
